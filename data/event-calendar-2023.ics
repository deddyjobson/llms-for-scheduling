BEGIN:VCALENDAR
VERSION:2.0
PRODID:-//researchr.org//conf.researchr.org//EN
CALSCALE:GREGORIAN

BEGIN:VEVENT
DTSTART:20230514T230000Z
DTEND:20230514T232000Z
DTSTAMP:20240331T110121Z
UID:d8e24a47-c0ef-4c2a-87a2-4bea4440c64e@conf.researchr.org
CREATED:20230515T030746Z
SUMMARY:[MSR Technical Papers] Opening Session & Award Announcements - Emad Shihab\, Patanamon Thongtanunam\, Bogdan Vasilescu
DESCRIPTION:
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T052954Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230514T232000Z
DTEND:20230514T234000Z
DTSTAMP:20240331T110121Z
UID:24533eeb-10c1-4bb4-bb2e-37a293c8a0b8@conf.researchr.org
CREATED:20230515T030746Z
SUMMARY:[MSR Technical Papers] MSR 2023 Foundational Contribution Award - Audris Mockus
DESCRIPTION:
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T052954Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230514T234000Z
DTEND:20230515T000000Z
DTSTAMP:20240331T110121Z
UID:4fff4562-06e9-47bb-95e4-6d35e18c3441@conf.researchr.org
CREATED:20230515T030746Z
SUMMARY:[MSR Technical Papers] MSR 2023 Ric Holt Early Career Achievement Award - Li Li
DESCRIPTION:
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T052953Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T000000Z
DTEND:20230515T003000Z
DTSTAMP:20240331T110121Z
UID:fbada2f6-f120-4db8-b59a-ba137d1db436@conf.researchr.org
CREATED:20230515T030746Z
SUMMARY:[MSR Technical Papers] MIP #1: Mining Source Code Repositories at Massive Scale Using Language Modeling - Miltiadis Allamanis\, Charles Sutton
DESCRIPTION:
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T052952Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T010000Z
DTEND:20230515T011200Z
DTSTAMP:20240331T110121Z
UID:971f87c1-c8ba-43e7-b4e5-920a6db94aee@conf.researchr.org
CREATED:20230515T025739Z
SUMMARY:[MSR Technical Papers] Understanding the Time to First Response In GitHub Pull Requests - Kazi Amit Hasan\, Marcos Macedo\, Yuan Tian\, Bram Adams\, Ding Steven\, H.\, H.
DESCRIPTION:The pull-based development paradigm is widely adopted by modern open-source software (OSS) projects\, enabling a pull request (PR) to pass through multiple validation stages\, from PR assignment and continuous integration testing to the actual code review\, before eventually being merged into the project or rejected. Due to the distributed collaboration characteristics of open-source projects\, PRs often get delayed across the PR stages\, including for the first response\, slowing down software development. \nIn this paper\, we conduct an exploratory study on the time-to-first-response. By analyzing 111\,094 closed pull requests from ten popular OSS projects on GitHub\, we find that bots are frequently used to generate the first response in a PR. The timing of those bot-generated first responses is significantly different from the human one. We further conduct an empirical study to understand the characteristics of the bot- and human-generated first responses\, including their relationship with the lifetime of a PR. The results of our study indicate that the presence of a bot is an important factor explaining the time-to-first-response in the pull-based development paradigm and\, thus\, has to be separately analyzed from human responses. Moreover\, we also find that projects with a low PR success rate\, heavy existing developer team workload\, and newly created projects have a higher correlation with a longer waiting time for the first human response to a pull request. These findings are important for newcomers to understand the delays they experience for their pull requests.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T044833Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T011200Z
DTEND:20230515T012400Z
DTSTAMP:20240331T110121Z
UID:858ee3b9-6ce7-4918-8fd3-d8a89bfa0e54@conf.researchr.org
CREATED:20230515T025739Z
SUMMARY:[MSR Technical Papers] Dealing with Popularity Bias in Recommender Systems for Third-party Libraries: How far Are We? - Phuong T. Nguyen\, Riccardo Rubei\, Juri Di Rocco\, Claudio Di Sipio\, Davide Di Ruscio\, Massimiliano Di Penta
DESCRIPTION:Recommender systems for software engineering (RSSEs) assist software engineers in dealing with a growing information overload when discerning alternative development solutions. While RSSEs are becoming more and more effective in suggesting handy recommendations\, they tend to suffer from popularity bias\, i.e.\, they favor items that are relevant mainly because several developers are using them. While this rewards artifacts that are likely more reliable and well-documented\, it would also mean missing artifacts rarely used because they are very specific or more recent. This paper studies popularity bias in Third-Party Library (TPL) RSSEs. First\, we investigate whether state-of-the-art research in RSSEs has already tackled the issue of popularity bias. Then\, we quantitatively assess four existing TPL RSSEs\, exploring their capability to deal with the recommendation of popular items. Finally\, we propose a mechanism to defuse popularity bias in the recommendation list. The empirical study reveals that the issue of dealing with popularity in TPL recommender systems has not received adequate attention from the software engineering community. Among the surveyed work\, only one starts investigating the issue\, albeit getting a low prediction performance.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T044835Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T012400Z
DTEND:20230515T013000Z
DTSTAMP:20240331T110121Z
UID:c708a852-f95e-4e0b-a1cb-53bebef72d64@conf.researchr.org
CREATED:20230515T025739Z
SUMMARY:[MSR Technical Papers] Smart Contract Upgradeability on the Ethereum Blockchain Platform: An Exploratory Study - Ilham Qasse\, Mohammad Hamdaqa\, Björn Þór Jónsson
DESCRIPTION:Smart contracts are computerized self-executing contracts that contain clauses\, which are enforced once certain conditions are met. Smart contracts are immutable by design and cannot be modified once deployed\, which ensures trustlessness. Despite smart contracts’ immutability benefits\, upgrading contract code is still necessary for bug fixes and potential feature improvements. In the past few years\, the smart contract community introduced several practices for upgrading smart contracts. Upgradeable contracts are smart contracts that exhibit these practices and are designed with upgradeability in mind. During the upgrade process\, a new smart contract version is deployed with the desired modification\, and subsequent user requests will be forwarded to the latest version (upgraded contract). Nevertheless\, little is known about the characteristics of the upgrading practices\, how developers apply them\, and how upgrading impacts contract usage. \nThis paper aims to characterize smart contract upgrading patterns and analyze their prevalence based on the deployed contracts that exhibit these patterns. Furthermore\, we intend to investigate the reasons why developers upgrade contracts (e.g.\, introduce features\, fix vulnerabilities) and how upgrades affect the adoption and life span of a contract in practice. \nWe collect deployed smart contracts metadata and source codes to identify contracts that exhibit certain upgrade patterns (upgradeable contracts) based on a set of policies. Then we trace smart contract versions for each upgradable contract and identify the changes in contract versions using similarity and vulnerabilities detection tools. Finally\, we plan to analyze the impact of upgrading on contract usage based on the number of transactions received and the lifetime of the contract version.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T044836Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T013000Z
DTEND:20230515T013600Z
DTSTAMP:20240331T110121Z
UID:2ce95f84-7ab7-4a08-b5ac-7fcccf5bdfbd@conf.researchr.org
CREATED:20230515T025739Z
SUMMARY:[MSR Technical Papers] An Exploratory Study of Ad Hoc Parsers in Python - Michael Schröder\, Jürgen Cito
DESCRIPTION:Ad hoc parsers are pieces of code that use common string functions like split\, trim\, or slice to effectively perform parsing. Whether it is handling command-line arguments\, reading configuration files\, parsing custom file formats\, or any number of other minor string processing tasks\, ad hoc parsing is ubiquitous—yet poorly understood. \nThis study aims to reveal the common syntactic and semantic characteristics of ad hoc parsing code in real world Python projects. Our goal is to understand the nature of ad hoc parsers in order to inform future program analysis efforts in this area. \nWe plan to conduct an exploratory study based on large-scale mining of open-source Python repositories from GitHub. We will use program slicing to identify program fragments related to ad hoc parsing and analyze these parsers and their surrounding contexts across 9 research questions using 25 initial syntactic and semantic metrics. Beyond descriptive statistics\, we will attempt to identify common parsing patterns by cluster analysis.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T044839Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T013600Z
DTEND:20230515T014200Z
DTSTAMP:20240331T110121Z
UID:7e5961bf-ed68-47da-a62d-9f2203ca43d3@conf.researchr.org
CREATED:20230515T025739Z
SUMMARY:[MSR Technical Papers] Improving Agile Planning for Reliable Software Delivery - Jirat Pasuksmit\, Fan Jiang\, Kemp Thornton\, Arik Friedman\, Natalija Fuksmane\, Isabelle Kohout\, Julian Connor
DESCRIPTION:Agile software development prioritizes the delivery of working software. However\, there are challenges in the sprint planning process that could impact the reliability of sprint delivery. In this paper\, we list three challenges related to the sprint planning process. We also discuss future work directions to facilitate the sprint planning process and mitigate those challenges for software teams.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T044840Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T010000Z
DTEND:20230515T011200Z
DTSTAMP:20240331T110121Z
UID:5caa37ba-bc8f-43e7-9c32-9ee1067d43dc@conf.researchr.org
CREATED:20230515T030100Z
SUMMARY:[MSR Technical Papers] AutoML from Software Engineering Perspective: Landscapes and Challenges - Chao Wang\, Zhenpeng Chen\, Minghui Zhou
DESCRIPTION:Machine learning (ML) has been widely adopted in modern software\, but the manual configuration of ML (e.g.\, hyper-parameter configuration) poses a significant challenge to software developers. Therefore\, automated ML (AutoML)\, which seeks the optimal configuration of ML automatically\, has received increasing attention from the software engineering community. However\, to date\, there is no comprehensive understanding of how AutoML is used by developers and what challenges developers encounter in using AutoML for software development. To fill this knowledge gap\, we conduct the first study on understanding the use and challenges of AutoML from software developers’ perspective. We collect and analyze 1\,554 AutoML downstream repositories\, 769 AutoML-related Stack Overflow questions\, and 1\,437 relevant GitHub issues. The results suggest the increasing popularity of AutoML in a wide range of topics\, but also the lack of relevant expertise. We manually identify specific challenges faced by developers for AutoML-enabled software. Based on the results\, we derive a series of implications for AutoML framework selection\, framework development\, and research. Code scripts and datasets are publicly available.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T045114Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T011200Z
DTEND:20230515T012400Z
DTSTAMP:20240331T110121Z
UID:97473657-ba0a-409e-b847-a315e628e67e@conf.researchr.org
CREATED:20230515T030100Z
SUMMARY:[MSR Technical Papers] Characterizing and Understanding Software Security Vulnerabilities in Machine Learning Libraries - Nima Shiri Harzevili\, Jiho Shin\, Junjie Wang\, Song Wang\, Nachiappan Nagappan
DESCRIPTION:The application of machine learning (ML) libraries has tremendously increased in many domains\, including autonomous driving systems\, medical\, and critical industries. Vulnerabilities of such libraries could result in irreparable consequences. However\, the characteristics of software security vulnerabilities have not been well studied. In this paper\, to bridge this gap\, we take the first step towards characterizing and understanding the security vulnerabilities of seven well- known ML libraries\, including TensorFlow\, PyTorch\, Scikit-learn\, Mlpack\, Pandas\, Numpy\, and Scipy. To do so\, we collected 683 security vulnerabilities to explore four major factors: 1) vulnerability types\, 2) root causes\, 3) symptoms\, and 4) fixing patterns of security vulnerabilities in ML libraries. The findings of this study can help developers and researchers understand the characteristics of security vulnerabilities across different ML libraries.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T045117Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T012400Z
DTEND:20230515T013000Z
DTSTAMP:20240331T110121Z
UID:02ae50e9-248c-4614-a556-41206656f712@conf.researchr.org
CREATED:20230515T030100Z
SUMMARY:[MSR Technical Papers] DeepScenario: An Open Driving Scenario Dataset for Autonomous Driving System Testing - Chengjie Lu\, Tao Yue\, Shaukat Ali
DESCRIPTION:With the rapid development of autonomous driving systems (ADSs)\, testing ADSs under various environmental conditions has become a key method to ensure the successful deployment of ADS in the real world. However\, it is impossible to test all the scenarios due to the inherent complexity and uncertainty of ADSs and the driving tasks. Further\, testing of ADSs is expensive regarding time and computational resources. Therefore\, a large-scale driving scenario dataset consisting of various driving conditions is needed. To this end\, we present an open driving scenario dataset $\mathrm{DeepScenario}$\, containing over 30\textit{K} \textit{executable} driving scenarios\, which are collected by 2880 test executions of three driving scenario generation strategies. Each scenario in the dataset is labeled with six attributes characterizing test results. We further show the attribute statistics and distribution of driving scenarios. For example\, there are 1050 collision scenarios\, in 917 scenarios there were collisions with other vehicles\, 105 and 28 with pedestrians and static obstacles\, respectively. Target users include ADS developers who need to validate their systems under various environmental conditions.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T045115Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T013000Z
DTEND:20230515T013600Z
DTSTAMP:20240331T110121Z
UID:2cc6ead8-24f0-4ec2-86c7-1e03f8b3fa51@conf.researchr.org
CREATED:20230515T030100Z
SUMMARY:[MSR Technical Papers] NICHE: A Curated Dataset of Engineered Machine Learning Projects in Python - Ratnadira Widyasari\, Zhou Yang\, Ferdian Thung\, Sheng Qin Sim\, Fiona Wee\, Camellia Lok\, Jack Phan\, Haodi Qi\, Constance Tan\, Qijin Tay\, David Lo
DESCRIPTION:Machine learning (ML) has gained much attention and been incorporated into our daily lives. While there are numerous publicly available ML projects on open source platforms such as GitHub\, there have been limited attempts in filtering those projects to curate ML projects of high quality. The limited availability of such high-quality dataset poses an obstacle in understanding ML projects. To help clear this obstacle\, we present NICHE\, a manually labelled dataset consisting of 572 ML projects. Based on evidences of good software engineering practices\, we label 441 of these projects as engineered and 131 as non-engineered. This dataset can help researchers understand the practices that are followed in high-quality ML projects. It can also be used as a benchmark for classifiers designed to identify engineered ML projects.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T045116Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T013600Z
DTEND:20230515T014200Z
DTSTAMP:20240331T110121Z
UID:92d619ec-5403-4536-86c6-633f7a62e185@conf.researchr.org
CREATED:20230515T030100Z
SUMMARY:[MSR Technical Papers] PTMTorrent: A Dataset for Mining Open-source Pre-trained Model Packages - Wenxin Jiang\, Nicholas Synovic\, Purvish Jajal\, Taylor R. Schorlemmer\, Arav Tewari\, Bhavesh Pareek\, George K. Thiruvathukal\, James C. Davis
DESCRIPTION:Due to the cost of developing and training deep learning models from scratch\, machine learning engineers have begun to reuse pre-trained models (PTMs) and fine-tune them for downstream tasks. PTM registries known as “model hubs” support engineers in distributing and reusing deep learning models. PTM packages include pre-trained weights\, documentation\, model architectures\, datasets\, and metadata. Mining the information in PTM packages will enable the discovery of engineering phenomena and tools to support software engineers. However\, accessing this information is difficult — there are many PTM registries\, and both the registries and the individual packages may have rate limiting for accessing the data. We present an open-source dataset\, PTMTorrent\, to facilitate the evaluation and understanding of PTM packages. This paper describes the creation\, structure\, usage\, and limitations of the dataset. The dataset includes a snapshot of 5 model hubs and a total of 15\,913 PTM packages. These packages are represented in a uniform data schema for cross-hub mining. We describe prior uses of this data and suggest research opportunities for mining using our dataset. %2F%7E%2F.The PTMTorrent dataset (v1) is available at: https://app.globus.org/file-manager?origin_id=55e17a6e-9d8f-11ed-a2a2-8383522b48d9&amp\;origin_path= Our dataset generation tools are available on GitHub: https://doi.org/10.5281/zenodo.7570357.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T045118Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T015000Z
DTEND:20230515T020200Z
DTSTAMP:20240331T110121Z
UID:6502bbce-f841-4a9d-8e8f-63bae7f4c337@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Evaluating Software Documentation Quality - Henry Tang\, Sarah Nadi
DESCRIPTION:The documentation of software libraries is an essential resource for learning how to use the library. Bad documentation may demotivate a developer from using the library or may result in incorrect usage of the library. Therefore\, as developers select which libraries to use and learn\, it would be beneficial to know the quality of the available documentation. In this paper\, we follow a systematic process to create an automatic documentation quality evaluation tool. We identify several documentation quality aspects from the literature and design metrics that measure these aspects. We design a documentation quality overview visualization to visualize and present these metrics\, and receive intermediate feedback through a focused interview study. Based on the received feedback\, we implement a web service that can evaluate a given documentation page for Java\, JavaScript\, and Python libraries.We use this web service to conduct a survey with 26 developers where we evaluate the usefulness of our metrics as well as whether they reflect developers’ experiences when using this library. Our results show that participants rated most of our metrics highly\, with Text Readability\, and Code Readability (of examples) receiving the highest ratings. We also found several libraries where our evaluation reflected developers’ experiences using the library\, indicating the accuracy of our metrics.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185836Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T020200Z
DTEND:20230515T021400Z
DTSTAMP:20240331T110121Z
UID:48d969e7-e60e-43e9-8d52-b93c1056ba52@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] What Do Users Ask in Open-Source AI Repositories? An Empirical Study of GitHub Issues - Zhou Yang\, Chenyu Wang\, Jieke Shi\, Thong Hoang\, Pavneet Singh Kochhar\, Qinghua Lu\, Zhenchang Xing\, David Lo
DESCRIPTION:Artiﬁcial intelligence (AI) systems\, which beneﬁt from the availability of large-scale datasets and increasing computational power\, have become effective solutions to various critical tasks\, such as natural language understanding\, speech recognition\, and image processing. The advancement of these AI systems are inseparable from open-source software (OSS). Specifically\, many benchmarks\, implementations\, and frameworks for constructing AI systems are made open source and accessible to the general public\, allowing researchers and practitioners to reproduce the reported results and broaden the application of AI systems. The development of AI systems follows a data-driven paradigm and is sensitive to hyperparameter settings and data separation. Developers may encounter unique problems when employing open-source AI repositories. \nThis paper presents an empirical study that investigates the issues in the repositories of open-source AI repositories to assist developers in understanding problems during the process of employing AI systems. We collect 576 repositories from the PapersWithCode platform. Among these repositories\, we ﬁnd 24\,953 issues by utilizing GitHub REST APIs. Our empirical study includes three phases. First\, we manually analyze these issues to categorize the problems that developers are likely to encounter in open-source AI repositories. Speciﬁcally\, we provide a taxonomy of 13 categories related to AI systems. The two most common issues are runtime errors (23.18%) and unclear instructions (19.53%). Second\, we see that 67.5% of issues are closed. We also ﬁnd that half of these issues resolve within four days. Moreover\, issue management features\, i.e.\, label and assign\, are not widely adopted in the open-source AI repositories. In particular\, only 7.81% and 5.9% of repositories label issues and assign these issues to assignees\, respectively. Finally\, we empirically show that employing GitHub issue management features and writing issues with detailed descriptions facilitate the resolution of issues. Based on our ﬁndings\, we make recommendations for developers to help better manage the issues of open-source AI repositories and improve their quality.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185836Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T021400Z
DTEND:20230515T022600Z
DTSTAMP:20240331T110121Z
UID:9f9262f1-af20-450b-ad41-c1269ec4952d@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] PICASO: Enhancing API Recommendations with Relevant Stack Overflow Posts - Ivana Clairine Irsan\, Ting Zhang\, Ferdian Thung\, Kisub Kim\, David Lo
DESCRIPTION:While having options could be liberating\, too many options could lead to the sub-optimal solution being chosen. This is not an exception in the software engineering domain. Nowa- days\, API has become imperative in making software developers’ life easier. APIs help developers implement a function faster and more efficiently. However\, given the large number of open- source libraries to choose from\, choosing the right APIs is not a simple task. Previous studies on API recommendation leverage natural language (query) to identify which API would be suitable for the given task. However\, these studies only consider one source of input\, i.e.\, GitHub or Stack Overflow\, independently. There are no existing approaches that utilize Stack Overflow to help generate better API sequence recommendations from queries obtained from GitHub. Therefore\, in this study\, we aim to provide a framework that could improve the result of the API sequence recommendation by leveraging information from Stack Overflow. In this work\, we propose PICASO\, which leverages a bi- encoder to do contrastive learning and a cross-encoder to build a classification model in order to find a semantically similar Stack Overflow given an annotation (i.e.\, code comment). Subsequently\, PICASO then uses the Stack Overflow’s title as a query expansion. PICASO then uses the extended queries to fine-tune a CodeBERT\, resulting in an API sequence generation model. Based on our experiments\, we found that incorporating the Stack Overflow title into CodeBERT would improve the performance of API sequence generation’s BLEU-4 score by 10.8%.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185836Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T022600Z
DTEND:20230515T023200Z
DTSTAMP:20240331T110121Z
UID:09ea2824-f802-4175-8ec6-94ccc61917cd@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] GIRT-Data: Sampling GitHub Issue Report Templates - Nafiseh Nikehgbal\, Amir Hossein Kargaran\, Abbas Heydarnoori\, Hinrich Schütze
DESCRIPTION:GitHub’s issue reports provide developers with valuable information that is essential to the evolution of a software development project. Contributors can use these reports to perform software engineering tasks like submitting bugs\, requesting features\, and collaborating on ideas. In the initial versions of issue reports\, there was no standard way of using them. As a result\, the quality of issue reports varied widely. To improve the quality of issue reports\, GitHub introduced issue report templates (IRTs)\, which pre-fill issue descriptions when a new issue is opened. An IRT usually contains greeting contributors\, describing project guidelines\, and collecting relevant information. However\, despite of effectiveness of this feature which was introduced in 2016\, only nearly 5% of GitHub repositories (with more than 10 stars) utilize it. There are currently few articles on IRTs\, and the available ones only consider a small number of repositories. In this work\, we introduce GIRT-Data\, the first and largest dataset of IRTs in both YAML and Markdown format. This dataset and its corresponding open-source crawler tool are intended to support research in this area and to encourage more developers to use IRTs in their repositories. The stable version of the dataset contains 1\,084\,300 repositories and 50\,032 of them support IRTs. The stable version of the dataset and crawler is available here: https://github.com/kargaranamir/girt-data
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185836Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T015000Z
DTEND:20230515T015600Z
DTSTAMP:20240331T110121Z
UID:d23a40d8-506f-4c4d-a7ca-6b2e10676f53@conf.researchr.org
CREATED:20230426T174738Z
SUMMARY:[MSR Technical Papers] TypeScript's Evolution: An Analysis of Feature Adoption Over Time - Joshua D. Scarsbrook\, Mark Utting\, Ryan K. L. Ko
DESCRIPTION:TypeScript is a quickly evolving superset of JavaScript with active development of new features. Our paper seeks to understand how quickly these features are adopted by the developer community. Existing work in JavaScript shows the adoption of dynamic language features can be a major hindrance to static analysis. As TypeScript evolves the addition of features makes the underlying standard more and more difficult to keep up with. In our work we present an analysis of 500 open source TypeScript repositories and study the adoption of 13 language features over the past three years. We show that while new versions of the TypeScript compiler are aggressively adopted by the community the same cannot be said for language features. While some experience strong growth others are rarely adopted by projects. Our work serves as a starting point for future study of the adoption of features in TypeScript. We also release our analysis and data gathering software as open source in the hope it helps the programming languages community. \nSource Code: https://github.com/Vbitz/jsdata_msr
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230502T190936Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T015600Z
DTEND:20230515T020200Z
DTSTAMP:20240331T110121Z
UID:88cf20d3-62bb-491f-9e41-4ad16fedb9f4@conf.researchr.org
CREATED:20230426T174738Z
SUMMARY:[MSR Technical Papers] DGMF: Fast Generation of Comparable\, Updatable Dependency Graphs for Software Repositories - Tobias Litzenberger\, Johannes Düsing\, Ben Hermann
DESCRIPTION:Dependency graphs for software repositories have been utilized in a variety of different research contexts. However\, to this date there is no unified data model for such graphs\, often prompting researchers to implement domain-specific methodologies from scratch. This greatly hinders comparability and makes it hard to incorporate existing tooling into new contexts.With this work we propose DGMF\, a framework for mining dependency graphs via repository-specific\, user-defined adapters. DGMF is designed to be fast\, to require little repository-specific code\, and to produce graphs that are comparable even across different repositories. We present our design and implementation\, as well as three predefined adapters and an evaluation.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230502T190936Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T020200Z
DTEND:20230515T020800Z
DTSTAMP:20240331T110121Z
UID:4ecbea7f-c955-4185-9636-cc8a90369edd@conf.researchr.org
CREATED:20230426T174738Z
SUMMARY:[MSR Technical Papers] Enabling Analysis and Reasoning on Software Systems through Knowledge Graph Representation - Satrio Adi Rukmono\, Michel Chaudron
DESCRIPTION:This work presents a knowledge-representation-based approach for analysing software systems. Its main components are: a generic and extensible knowledge model\, and a knowledge extractor tool that generates instance-level knowledge graphs from software repositories (currently Java). Our knowledge model can be used as a shared data-model in a software analysis pipeline. We illustrate the potential uses of our knowledge representation by performing experimental architecture recovery and identifying design pattern instance. We intend to use our ontology and extraction tool as a partial foundation for automated reasoning on software systems.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230502T190937Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T020800Z
DTEND:20230515T021400Z
DTSTAMP:20240331T110121Z
UID:1595249c-c141-4a26-9894-d475184f121b@conf.researchr.org
CREATED:20230426T174738Z
SUMMARY:[MSR Technical Papers] microSecEnD: A Dataset of Security-Enriched Dataflow Diagrams for Microservice Applications - Simon Schneider\, Tufan Özen\, Michael Chen\, Riccardo Scandariato
DESCRIPTION:Dataflow diagrams (DFDs) are useful resources in securing applications since they show a software system’s architecture and allow assessing architectural security and weaknesses. Enriching them with annotations about implemented security features further strengthens this ability. This is especially true for microservice applications\, as their most pressing security concerns stem from their separation into multiple services. Researchers need data to work on these issues and enhance microservices’ architectural security. In this work\, we present microSecEnD\, a dataset of 17 manually created DFDs that are extensively annotated with information on implemented security features. We provide traceability for all model items. Further\, a mapping to a list of 17 architectural security best-practices is provided. Finally\, for each best-practice that an application violates\, we present a model variant that does adhere to it.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230502T190935Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T021400Z
DTEND:20230515T022600Z
DTSTAMP:20240331T110121Z
UID:59743a95-772c-4f0a-8f88-4fdd6963f628@conf.researchr.org
CREATED:20230426T174738Z
SUMMARY:[MSR Technical Papers] Wasmizer: Curating WebAssembly-driven Projects on GitHub - Alexander Nicholson\, Quentin Stiévenart\, Arash Mazidi\, Mohammad Ghafari
DESCRIPTION:WebAssembly is increasingly being used as a portable compilation target for high-level programming lan- guages. However\, the current datasets of WebAssembly programs only include binaries without their corresponding source code. Having the source code available along with the binaries would be helpful for tool writers\, and it would enable in-depth program analyses. We mined GitHub and collected 2540 C and C++ projects that are highly-related to WebAssembly. From these projects\, we extracted a dataset of 8915 binaries that belong to 572 projects and linked WebAssembly binaries to their source code. To demonstrate an application of this dataset\, we investigated the presence of eight WebAssembly compilation smells in a subset of these projects. We deployed Wasmizer\, a tool that regularly mines GitHub projects and makes an up-to- date dataset of WebAssembly sources and their binaries publicly available
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230502T190934Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T022600Z
DTEND:20230515T023200Z
DTSTAMP:20240331T110121Z
UID:1999ad98-7fa3-455d-b164-7a4fa5193dc9@conf.researchr.org
CREATED:20230426T174738Z
SUMMARY:[MSR Technical Papers] Feature Toggle Usage Patterns : A Case Study on Google Chromium - Md Tajmilur Rahman
DESCRIPTION:Feature toggles control the state of features and allow exposing unfinished features to a reduced cohort of users without affecting the general software operation. It is basically a variable used in if conditions to control the flow of program execution. Since there is no universal standard of using feature toggles established yet\, developers write code around feature toggles and use them spontaneously. Certain usage patterns of feature toggles may even lead to code smells. In this short paper we introduce six different toggle usage patterns from Google Chromium and discuss the possible reasons\, consequences\, and detection methods. We further conduct a mixed-method approach to analyze them. Since this study is still in progress\, we report our early results only for the three most commonly appeared usage patterns. We validate our quantitative findings with the qualitative results obtained by interviewing 15 Google developers. We found that there are 3.1K toggles present in 38 components of Chromium. In the median case\, nested toggles are shared by 5 different files\, spread toggles span 2 different components\, and dead toggles cover an average of 4 lines of code (loc). Novel aspects:- Although usage patterns of C pre-processors (#ifdef s) are studied in the past\, we did not find any study particularly focusing on the run-time feature toggles usage patterns. Hence\, we have been inspired to do an exploratory study to investigate different usage patterns of feature toggles. We chose Google Chromium as a case study at this point since Google developers use feature toggles extensively.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230502T190933Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T034500Z
DTEND:20230515T041500Z
DTSTAMP:20240331T110121Z
UID:a8f46bf1-3c29-4d57-a959-eca1e2892743@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] MIP #2: The Impact of Tangled Code Changes - Kim Herzig\, Andreas Zeller
DESCRIPTION:
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185946Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T042000Z
DTEND:20230515T043200Z
DTSTAMP:20240331T110121Z
UID:b36e944d-650f-4d4e-a8f5-8f37e78f316c@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] On Codex Prompt Engineering for OCL Generation: An Empirical Study - Seif Abukhalaf\, Mohammad Hamdaqa\, Foutse Khomh
DESCRIPTION:The Object Constraint Language (OCL) is a declar- ative language that provides constraint and object query expres- sions on any MOF model. OCL can be used to add precision and conciseness to the UML models. Despite its advantages\, the unfamiliar syntax of OCL contributed to its lower adoption by software practitioners. This paper experiments with prompt engineering and Large Language Models (LLM) for OCL con- straint generation from natural language. LLMs\, such as GPT-3\, have achieved substantial gains in many NLP tasks\, including text generation and semantic parsing. Similarly\, researchers have improved on downstream tasks by fine-tuning the LLMs for the target task. Codex\, a GPT-3 descendant by OpenAI\, is fine-tuned on publicly available code from GitHub and has proven the ability to generate code in many programming languages\, powering the AI-pair programmer Copilot. One way to exploit Codex is to engineer prompts for the downstream task. In this paper\, we investigate the reliability of the OCL constraints generated by Codex\, given the specification in natural language. To accomplish this\, we collected a dataset of 15 UML models with 169 specifica- tions and followed a prompt engineering approach. We manually crafted a template with slots to fill in the UML information and task description\, following the prefix shape to complete the template with the generated OCL constraint. Both zero- and few-shot learning methods were adopted in the experiments. The evaluation is reported by measuring the syntactic validity and the execution accuracy scores of the generated OCL constraints. Our findings suggest that by enriching the prompts with the UML information of the model and with influence from the correct behaviour of the few-shot examples\, the reliability of the generated OCL constraints increases. In addition\, we also investigated their similarity by calculating the cosine metric between the correctly generated OCL constraints and their corresponding human-written ground truth. The results indicate that\, on average\, the generated OCL constraints were similar to their ground truth.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185946Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T043200Z
DTEND:20230515T044400Z
DTSTAMP:20240331T110121Z
UID:84340b55-4a8b-4a65-8f51-b4dff6174ed4@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Cross-Domain Evaluation of a Deep Learning-Based Type Inference System - Bernd Gruner\, Tim Sonnekalb\, Thomas S. Heinze\, Clemens-Alexander Brust
DESCRIPTION:Optional type annotations allow for enriching dynamic programming languages with static typing features like better Integrated Development Environment (IDE) support\, more precise program analysis\, and early detection and prevention of type-related runtime errors. Machine learning-based type inference promises interesting results for automating this task. However\, the practical usage of such systems depends on their ability to generalize across different domains\, as they are often applied outside their training domain. In this work\, we investigate Type4Py as a representative of state-of-the-art deep learning-based type inference systems\, by conducting extensive cross-domain experiments. Thereby\, we address the following problems: class imbalances\, out-of-vocabulary words\, dataset shifts\, and unknown classes. To perform such experiments\, we use the datasets ManyTypes4Py and CrossDomainTypes4Py. The latter we introduce in this paper. Our dataset enables the evaluation of type inference systems in different domains of software projects and has over 1\,000\,000 type annotations mined on GitHub and Libraries. It consists of data from the two domains web development and scientific calculation. Through our experiments\, we detect that the shifts in the dataset and the long-tailed distribution with many rare and unknown data types decrease the performance of the deep learning-based type inference system drastically. In this context\, we test unsupervised domain adaptation methods and fine-tuning to overcome these issues. Moreover\, we investigate the impact of out-of-vocabulary words.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185946Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T044400Z
DTEND:20230515T045600Z
DTSTAMP:20240331T110121Z
UID:28651beb-7ff8-4a3f-8994-bfd6f7cad5bc@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Enriching Source Code with Contextual Data for Code Completion Models: An Empirical Study - Tim van Dam\, Maliheh Izadi\, Arie van Deursen
DESCRIPTION:Abstract—Transformer-based pre-trained models have recently achieved great results in solving many software engineering tasks including automatic code completion which is a staple in a developer’s toolkit. While many have striven to improve the code- understanding abilities of such models\, the opposite – making the code easier to understand – has not been properly investigated. In this study\, we aim to answer whether making code easier to understand through using contextual data improves the perfor- mance of pre-trained code language models for the task of code completion. We consider type annotations and comments as two common forms of additional contextual information that often help developers understand code better. For the experiments\, we study code completion in two granularity levels\; token and line completion and take three recent and large-scale language models for source code: UniXcoder\, CodeGPT\, and InCoder with five evaluation metrics. Finally\, we perform the Wilcoxon Signed Rank test to gauge significance and measure the effect size. Contrary to our expectations\, all models perform better if type annotations are removed (albeit the effect sizes are small). For comments\, we find that the models perform better in the presence of multi-line comments (again with small effect sizes). Based on our observations\, we recommend making proper design choices when training\, fine-tuning\, or simply selecting such models given the intended data and application. Better evaluations and multi- modal techniques can also be further investigated to improve the practicality and accuracy of auto-completions.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T064138Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T045600Z
DTEND:20230515T050800Z
DTSTAMP:20240331T110121Z
UID:57221e02-5d9f-45b8-916a-e2c5d1899825@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Model-Agnostic Syntactical Information for Pre-Trained Programming Language Models - Iman Saberi\, Fatemeh Hendijani Fard
DESCRIPTION:Abstract—Pre-trained Programming Language Models (PPLMs) achieved many recent states of the art results for many code-related software engineering tasks. Though some studies use data flow or propose tree-based models that utilize Abstract Syntax Tree (AST)\, most PPLMs do not fully utilize the rich syntactical information in source code. Still\, the input is considered a sequence of tokens. There are two issues\; the first is computational inefficiency due to the quadratic relationship between input length and attention complexity. Second\, any syntactical information\, when needed as an extra input to the current PPLMs\, requires the model to be pre-trained from scratch\, wasting all the computational resources already used for pre-training the current models. In this work\, we propose Named Entity Recognition (NER) adapters\, lightweight modules that can be inserted into Transformer blocks to learn type information extracted from the AST. These adapters can be used with current PPLMs such as CodeBERT\, GraphCodeBERT\, and CodeT5. We train the NER adapters using a novel Token Type Classification objective function (TTC). We insert our proposed work in CodeBERT\, building CodeBERTER\, and evaluate the performance on two tasks of code refinement and code summarization. CodeBERTER improves the accuracy of code refinement from 16.4 to 17.8 while using 80% of training parameter budget compared to the fully fine-tuning approach\, and the BLEU score of code summarization from 14.75 to 15.90 while reducing 77% of training parameters compared to the fully fine-tuning approach.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185946Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T042000Z
DTEND:20230515T043200Z
DTSTAMP:20240331T110121Z
UID:9a71efc3-5a2e-440e-a534-40b0e8ece37c@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] What Happens When We Fuzz? Investigating OSS-Fuzz Bug History - Brandon Keller\, Benjamin S. Meyers\, Andrew Meneely
DESCRIPTION:BACKGROUND: Software engineers must be vigilant in preventing and correcting vulnerabilities and other critical bugs. In servicing this need\, numerous tools and techniques have been developed to assist developers. Fuzzers\, by autonomously generating inputs to test programs\, promise to save time by detecting memory corruption\, input handling\, exception cases\, and other issues. \nAIMS: The goal of this work is to empower developers to prioritize their quality assurance by analyzing the history of bugs generated by OSS-Fuzz. Specifically\, we examined what has happened when a project adopts fuzzing as a quality assurance practice by measuring bug lifespans\, learning opportunities\, and bug types. \nMETHOD: We analyzed 44\,102 reported issues made public by OSS-Fuzz prior to March 12\, 2022. We traced the Git commit ranges reported by repeated fuzz testing to the source code repositories to identify how long fuzzing bugs remained in the system\, who fixes these bugs\, and what types of problems fuzzers historically have found. We identified the bug-contributing commits to estimate when the bug containing code was introduced\, and measure the timeline from introduction to detection to fix. \nRESULTS: We found that bugs detected in OSS-Fuzz have a median lifespan of 324 days\, but that bugs\, once detected\, only remain unaddressed for a median of 2 days. Further\, we found that of the 8\,099 issues for which a source committing author can be identified\, less than half (45.9%) of issues were fixed by the same author that introduced the bug. \nCONCLUSIONS: The results show that fuzzing can be used to makes a positive impact on a project that takes advantage in terms of their ability to address bugs in a time frame conducive to fixing mistakes prior to a product release. However\, the rate at which we find authors are not correcting their own errors suggests that not all developers are benefiting from the learning opportunities provided by fuzzing feedback.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T031936Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T043200Z
DTEND:20230515T044400Z
DTSTAMP:20240331T110121Z
UID:abbc2dc8-3bfb-4054-b1f8-3b1088799973@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] An Empirical Study of High Performance Computing (HPC) Performance Bugs - Md Abul Kalam Azad\, Nafees Iqbal\, Foyzul Hassan\, Probir Roy
DESCRIPTION:Performance efficiency and scalability are the major design goals for high performance computing (HPC) applications. However\, it is challenging to achieve high efficiency and scalability for such applications due to complex underlying hardware architecture\, inefficient algorithm implementation\, suboptimal code generation by the compilers\, inefficient parallelization\, and so on. As a result\, the HPC community spends a significant effort detecting and fixing the performance bugs frequently appearing in scientific applications. However\, it is important to accumulate the experience to guide the scientific software engineering community to write performance-efficient code. \nIn this paper\, we investigate open-source HPC applications to categorize the performance bugs and their fixes and measure the programmer’s effort and experience to fix them. For this purpose\, we first perform a large-scale empirical analysis on 1729 HPC performance commits collected from 23 real-world projects. Through our manual analysis\, we identify 186 performance issues from these projects. Furthermore\, we study the root cause of these performance issues and generate a performance bug taxonomy for HPC applications. Our analysis identifies that inefficient algorithm implementation (39.3%)\, inefficient code for target micro-architecture (31.2%)\, and missing parallelism and inefficient parallelization (14.5%) are the top three most prevalent categories of performance issues for HPC applications. Additionally\, to understand how the performance bugs are fixed\, we analyze the performance fix commits and categorize them into eight performance fix types. We further measure the time it takes to discover a performance bug and the developer’s efforts and expertise required to fix them. The analysis identified that it’s difficult to localize performance inefficiencies\, and once localized\, fixes are complicated with a median patch size (LOC) of 35 lines and are mostly fixed by experienced developers.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T081300Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T044400Z
DTEND:20230515T045000Z
DTSTAMP:20240331T110121Z
UID:ed5ba878-d361-49c8-8c07-fa06c4c9e601@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Semantically-enriched Jira Issue Tracking Data - Themistoklis Diamantopoulos\, Dimitrios-Nikitas Nastos\, Andreas Symeonidis
DESCRIPTION:Current state of practice dictates that software developers host their projects online and employ project management systems to monitor the development of product features\, keep track of bugs\, and prioritize task assignments. The data stored in these systems\, if their semantics are extracted effectively\, can be used to answer several interesting questions\, such as finding who is the most suitable developer for a task\, what the priority of a task should be\, or even what is the actual workload of the software team. To support researchers and practitioners that work towards these directions\, we have built a system that crawls data from the Jira management system\, performs topic modeling on the data to extract useful semantics and stores them in a practical database schema. We have used our system to retrieve and analyze 656 projects of the Apache Software Foundation\, comprising data from more than a million Jira issues.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T031936Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T045000Z
DTEND:20230515T045600Z
DTSTAMP:20240331T110121Z
UID:4d0f1c3f-2af6-4a1b-8082-f5a3e4c43824@conf.researchr.org
CREATED:20230502T181157Z
SUMMARY:[MSR Technical Papers] An exploratory study of bug introducing changes: what happens when bugs are introduced in open source software? - Lukas Schulte\, Anamaria Mojica-Hanke\, Mario Linares-Vasquez\, Steffen Herbold
DESCRIPTION:Many studies consider the relation between individual aspects and bug introduction\, e.g.\, software testing and code review. Due to the design of the studies the results are usually only about correlations as interactions or interventions are not considered. \nWithin this study\, we want to narrow this gap and provide a broad empirical view on aspects of software development and their relation to bug introducing changes. \nWe consider the bugs\, the type of work when the bug was introduced\, aspects of the build process\, code review\, software tests\, and any other discussion related to the bug that we can identify. We use a qualitative approach that first describes variables of the development process and then groups the variables based on their relations. From these groups\, we can induce how their (pair-wise) interactions affect bug introducing changes.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T031936Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T045600Z
DTEND:20230515T050200Z
DTSTAMP:20240331T110121Z
UID:79f744f5-00af-4384-ab29-817ca8de73c6@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] HasBugs - Handpicked Haskell Bugs - Leonhard Applis\, Annibale Panichella
DESCRIPTION:We present HasBugs\, a manually collected Dataset of 25 Haskell Bugs from 6 Open Source Repositories. We provide buggy\, tested and fixed versions as well as reproduction packages and a summary of the bug and its context. For technical users\,the dataset is meant to either help researchers adopt techniques from other Languages for Haskell or to provide a human-verified gold standard for tool-evaluation. We also see applicability for qualitative research\, e.g. by analysis of bug-lifecycles and comparison to other languages. We provide a companion website for easy access and overview under https://ciselab.github.io/HasBugs/
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T031936Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T050200Z
DTEND:20230515T050800Z
DTSTAMP:20240331T110121Z
UID:913cf497-f945-4f4c-a991-e0005437aeff@conf.researchr.org
CREATED:20230502T184536Z
SUMMARY:[MSR Technical Papers] An Empirical Study on the Performance of Individual Issue Label Prediction - Jueun Heo\, Seonah Lee
DESCRIPTION:In GitHub\, open-source software (OSS) developers label issue reports. As issue labeling is a labor-intensive manual task\, automatic approaches have developed to label issue reports. However\, those approaches have shown a limited performance. Therefore\, it is necessary to analyze the performance of predicting labels for an issue report. Understanding the labels with high performance and those with low performance can help improve the performance of automatic issue labeling tasks. In this paper\, we investigate the performance of individual label prediction. Our investigation uncovers labels with high performance and those with low performance. Our results can help researchers to understand the different characteristics of labels and help the developer to develop a unified approach that combines several effective approaches for different kinds of issues.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T031936Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T054500Z
DTEND:20230515T063000Z
DTSTAMP:20240331T110121Z
UID:90a923c4-3158-470a-9025-7e8b6c2e0e19@conf.researchr.org
CREATED:20230515T030625Z
SUMMARY:[MSR Technical Papers] Tutorial: Recognizing Developers' Emotions Using Non-invasive Biometrics Sensors - Nicole Novielli
DESCRIPTION:Grounding on recent research in this field\, this tutorial will provide attendees with an overview on how to leverage biometrics for recognizing cognitive and affective states of software developers. Software development is an intellectual activity requiring creativity and problem-solving skills\, which are known to be influenced by emotions. Developers experience a wide range of affective states during programming tasks\, which may have an impact on their job performance and wellbeing. Early recognition of negative emotions\, such as stress or frustration can enable just-in-time intervention for developers and team managers\, in order to prevent burnout and undesired turnover. Attendees will have the possibility to familiarize with non-invasive biometric sensors for measuring that can be comfortably worn while programming. We will learn how to collect biometric data during software development activities\, how to preprocess them and how to extract features to be used for supervised training of emotion classifiers.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T031342Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T054500Z
DTEND:20230515T055700Z
DTSTAMP:20240331T110121Z
UID:b59352bc-6543-4db8-b6be-84eadecfd78f@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Investigating the Resolution of Vulnerable Dependencies with Dependabot Security Updates - Hamid Mohayeji Nasrabadi\, Andrei Agaronian\, Eleni Constantinou\, Nicola Zanone\, Alexander Serebrenik
DESCRIPTION:Modern software development practices increasingly rely on third-party libraries due to the inherent benefits of reuse. However\, libraries may contain security vulnerabilities that can propagate to the dependent applications. To counter this\, maintainers of dependent projects should monitor their dependencies and security reports to ensure that only patched releases of the upstream applications are in use. As manual maintenance of dependencies has shown to be ineffective\, several automated tools (aka bots) have been proposed to assist developers in rapidly identifying and resolving vulnerable dependencies. In this work\, we focus on Dependabot\, a popular bot providing security and version updates\, and study developers’ receptivity to its security updates in mature and actively maintained JavaScript projects. Moreover\, we carry out a fine-grained analysis of the lifecycle of every vulnerability to manifest how they are dealt with in the presence of Dependabot. Our findings show that the task of fixing vulnerable dependencies is\, to a large extent\, delegated to Dependabot and that developers merge the majority of security updates within several days. On the other hand\, when developers do not merge a security update\, they usually address the identified vulnerability manually. This approach\, however\, often takes up to several months which in turn could expose the projects to security issues.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T024125Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T055700Z
DTEND:20230515T060900Z
DTSTAMP:20240331T110121Z
UID:e64b4b77-691f-4f4c-ba69-a7ba74092632@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Unveiling the Relationship Between Continuous Integration and Code Coverage - José Diego Saraiva da Silva\, Daniel Alencar Da Costa\, Uirá Kulesza\, Gustavo Sizílio\, José Gameleira Neto\, Roberta Coelho\, Mei Nagappan
DESCRIPTION:Continuous integration (CI) is a software engineering practice that advocates the frequent integration of software through an automated build process. Existing research has explored the benefits of CI\, such as detecting errors earlier in the software life-cycle. Although CI places a heavy focus on automated tests\, it is still not clear whether CI is associated with better code coverage\, which could be a major benefit of using CI. To investigate whether CI is associated with an improvement in code coverage\, our work compares 30 projects that adopted CI (CI projects) and 30 projects that have never adopted CI (NOCI projects) to investigate the relationship between the evolution of code coverage and the adoption of CI. We observe that CI projects have more rising code coverage trends (50%) when compared to NOCI projects (10%). Additionally\, maintaining trends differ between CI and NOCI projects\; CI projects tend to stabilize their code coverage at a higher coverage value when compared to NOCI projects. We study the types of code changes that affect the coverage levels. We identify that projects that adopted CI substantially increased the number of code changes that rised code coverage in the projects. Finally\, our work reveals a positive association between CI and better code coverage.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T060900Z
DTEND:20230515T061500Z
DTSTAMP:20240331T110121Z
UID:706ae055-457d-436d-bf4e-28575c3dfee8@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] EGAD: A Moldable Tool for GitHub Action Analysis - Pablo Valenzuela-Toledo\, Alexandre Bergel\, Timo Kehrer\, Oscar Nierstrasz
DESCRIPTION:GitHub Actions (GA) enjoy increasing popularity in many software development projects as a means to automate repetitive software engineering tasks by enabling programmable event-driven workflows. Researchers and developers typically analyze GA at the raw data level using batch tools to mine and analyze actions\, jobs\, and steps within GA workflows. Although this approach is widely applicable\, it ignores the specific context of the GA workflow domain. Consequently\, researchers and developers do not reason directly about the domain abstractions. \nWe present our preliminary steps in building \tool (Explorable GitHub Action Domain Model)\, a moldable domain-specific tool to depict and analyze detailed GA workflow data. \tool consists of an explorable domain model of GA workflows augmented with custom\, domain-specific views\, and live narratives. We illustrate \tool in action using it to explore ``sticky commits'' in GitHub repositories.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T061500Z
DTEND:20230515T062100Z
DTSTAMP:20240331T110121Z
UID:80a33da8-c106-4984-bfb8-d01116d33dde@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] The Atlassian Data Lake: consolidating enriched software development data in a single\, queryable system - Arik Friedman\, Rohan Dhupelia\, Ben Jackson
DESCRIPTION:Managing work within and across multiple software teams requires a high level of visibility into the work of those teams\, to inform decisions on team velocity\, resource allocation\, and return on investment. Since much of the work is conducted in software development tools\, they are an essential source for consolidating and presenting a clear picture of the work being conducted. We describe the Atlassian Data Lake\, a solution that contains cross-product and cross-site data for easy analysis with pre-modeled and enriched fields to speed up insight generation. The Atlassian Data Lake enables practitioners and researchers to access software development tools data and derive software analytics without the overhead typically associated with data retrieval and post-processing.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230504T122559Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T062100Z
DTEND:20230515T062700Z
DTSTAMP:20240331T110121Z
UID:804e12b5-fb8f-447f-8161-8fbe498c14f0@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Are We Speeding Up or Slowing Down? On Temporal Aspects of Code Velocity - Gunnar Kudrjavets\, Nachiappan Nagappan\, Ayushi Rastogi
DESCRIPTION:This paper investigates how the duration of various code review periods changes over a projects’ lifetime. We study four open-source software (OSS) projects: Blender\, FreeBSD\, LLVM\, and Mozilla. We mine and analyze the characteristics of 283\,235 code reviews that cover\, on average\, seven years’ worth of development. Our main conclusion is that neither the passage of time or the project’s size impact code velocity. We find that (a) the duration of various code review periods (time-to-first-response\, time-to-accept\, and time-to-merge) for FreeBSD\, LLVM\, and Mozilla either becomes shorter or stays the same\; no directional trend is present for Blender\, (b) an increase in the size of the code bases (annually 3–17%) does not accompany a decrease in code velocity\, and (c) for FreeBSD\, LLVM\, and Mozilla\, the 30-day moving median stays in a fixed range for time-to-merge. These findings do not change with variabilities in code churn metrics\, such as the number of commits or distinct authors of code changes.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T063500Z
DTEND:20230515T064700Z
DTSTAMP:20240331T110121Z
UID:77af01e5-00c9-4a47-8484-ca5fb25925cb@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Energy Consumption Estimation of API-usage in Mobile Apps via Static Analysis - Abdul Ali Bangash\, Qasim Jamal\, Kalvin Eng\, Karim Ali\, Abram Hindle
DESCRIPTION:Smartphone application (app) developers measure or estimate the energy consumption of their apps to ensure that they are not consuming too much energy before releasing them to the end-users. However\, existing measurement and estimation techniques are cumbersome because they require developers to generate test cases and execute them on an expensive\, sophisticated hardware. To address these challenges\, we have proposed a static-analysis based approach that estimates the energy consumption of API usage in an app\, and eliminates the need for generating and executing test cases. To instantiate our approach\, we have created micro-benchmarks for the Swift SQLite API and measured the energy profile of its select\, insert\, and update operations. Given a Swift app\, we first scan it for uses of SQLite. We then combine that information with the measured energy profile to compute E-factor\, an estimate of the energy consumption of the API usage in an app. To showcase the viability of using E-factor in practice\, we calculate the E-factor of 56 real-world iOS apps\, and compare 16 versions and 11 methods to their hardware-based energy measurements. Our findings show that E-factor has a positive correlation with the hardware-based energy measurements. This result indicates that E-factor can be used as an estimate to compare the energy consumption difference in API usage across the different versions of an app. Additionally\, developers can use E-factor to identify which methods within their apps have the highest energy consumption and focus on optimizing those methods. Our approach is most useful in an Integrated Development Environment (IDE) or Continuous Integration/Continuous Deployment (CI/CD) pipeline\, where developers can receive warnings about high energy consumption in their app within milliseconds of making a modification to their code.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185701Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T064700Z
DTEND:20230515T065900Z
DTSTAMP:20240331T110121Z
UID:1f7ab5c9-1622-4492-924c-dd019b30e95a@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] An Exploratory Study on Energy Consumption of Dataframe Processing Libraries - Shriram Shanbhag\, Sridhar Chimalakonda
DESCRIPTION:The energy consumption of machine learning applications and their impact on the environment has recently gained attention as a research area\, focusing on the model creation and training/inference phases. However\, the data-oriented stages of the machine learning pipeline\, which involve preprocessing\, cleaning\, and exploratory analysis\, are critical components. However\, energy consumption during these stages has received limited attention. To fill this gap\, as a first step\, we aim to investigate the energy consumption of three popular dataframe processing libraries\, namely Pandas\, Vaex\, and Dask. We perform experiments across 21 dataframe processing operations within four categories\, utilizing three distinct datasets. Our results indicate that no single library is the most energy efficient for all tasks\, and the choice of a library can have a significant impact on energy consumption based on the types and frequencies of operations performed. The findings of this study suggest the potential for optimization of the energy consumption of data-oriented stages in the machine learning pipeline and warrant further research in this area.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185804Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T065900Z
DTEND:20230515T070500Z
DTSTAMP:20240331T110121Z
UID:74b07f3d-1971-4802-89ae-f6e37c68cb72@conf.researchr.org
CREATED:20230502T181919Z
SUMMARY:[MSR Technical Papers] Understanding issues related to personal data and data protection in open source projects on GitHub - Anne Hennig\, Lukas Schulte\, Steffen Herbold\, Oksana Kulyk\, Peter Mayer
DESCRIPTION:Data protection regulations such as the GDPR and the CCPA affect how software may handle the personal data of its users and how consent for handling of such data may be given. Prior literature focused on how this works in operation\, but lacks a perspective of the impact on the software development process. \nWithin our work\, we will address this gap and explore how software development itself is impacted. We want to understand which data protection-related issues are reported\, who reports them\, and how developers react to such issues. \nWe will conduct an exploratory study based on issues that are reported with respect to data protection in open source software on GitHub. We will determine the roles of the actors involved\, the status of such issues\, and we use inductive coding to understand the data protection issues. We qualitatively analyze the issues as part of the inductive coding and further explore the reasoning for resolutions. We quantitatively analyze the relation between the roles\, resolutions\, and data protection issues to understand correlations.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T233328Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T070500Z
DTEND:20230515T071700Z
DTSTAMP:20240331T110121Z
UID:961519a0-538c-4aec-acb1-5cf7383cd3d4@conf.researchr.org
CREATED:20230502T184615Z
SUMMARY:[MSR Technical Papers] Whistleblowing and Tech on Twitter - Laura Duits\, Isha Kashyap\, Joey Bekkink\, Kousar Aslam\, Emitzá Guzmán
DESCRIPTION:From airports to banks\, healthcare\, space crafts\, and even amazon services\, technology impacts almost every aspect of today’s life. If wrongdoings occur within or in relation to technology\, they can have big implications on individuals\, groups of people\, or society as a whole. Whistleblowers are insiders who expose such wrongdoings— eventually stopping misconducts\, such as fraud\, endangerment to public health and safety\, or damage to the environment. Twitter is a microblogging service that allows millions of users to share their views with people distributed all over the world on a daily basis. Tweets have the potential to contain useful information about whistleblowing in tech\, from the general public and whistleblowers. However\, until now this point has not been researched. To fill this gap\, we conducted an exploratory study on technology-related whistleblowing tweets by manually analysing tweets\, utilising descriptive statistics\, and machine learning techniques. We mined 7\,400 of tweets from whistleblowers themselves\, as well as news and opinions about certain whistleblowers and whistleblowing cases. Although our results show that only 30% of the tweets in our sample dataset (obtained through specific search terms) contained relevant information about whistleblowing in technology\, our analysis shows that tweets provide valuable information for both researchers and companies to understand the public opinion regarding whistleblowing cases. Furthermore\, we found that machine learning techniques are promising means for extracting information about whistleblowing in tech from the vast stream of tweets.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T185659Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T063500Z
DTEND:20230515T064700Z
DTSTAMP:20240331T110121Z
UID:9b95af0e-95ae-4424-abdd-8cf5d6133625@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] UNGOML: Automated Classification of unsafe Usages in Go - Anna-Katharina Wickert\, Clemens Damke\, Lars Baumgärtner\, Eyke Hüllermeier\, Mira Mezini
DESCRIPTION:The Go programming language offers strong protection from memory corruption. As an escape hatch of these protections\, it provides the unsafe package. Previous studies identified that this unsafe package is frequently used in real-world code for several purposes\, e.g.\, serialization or casting types. Due to the variety of these reasons\, it may be possible to refactor specific usages to avoid potential vulnerabilities. However\, the classification of unsafe usages is challenging and requires the context of the call and the program’s structure. In this paper\, we present the first automated classifier for unsafe usages in Go\, UNGOML\, to identify what is done with the unsafe package and why it is used. For UNGOML\, we built four custom deep-learning classifiers trained on a manually labeled data set. We represent Go code as enriched control-flow graphs (CFGs) and solve the label prediction task with one single-vertex and three context-aware classifiers. All three context-aware classifiers achieve a top-1 accuracy of more than 86% for both dimensions\, WHAT and WHY. Furthermore\, in a set-valued conformal prediction setting\, we achieve accuracies of more than 93% with mean label set sizes of 2 for both dimensions. Thus\, UNGOML can be used to efficiently filter unsafe usages for use cases such as refactoring or a security audit.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230602T110902Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T064700Z
DTEND:20230515T065900Z
DTSTAMP:20240331T110121Z
UID:1d75c823-a0f7-4831-8f1c-a49f0622546d@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Connecting the .dotfiles: Checked-In Secret Exposure with Extra (Lateral Movement) Steps - Gerhard Jungwirth\, Aakanksha Saha\, Michael Schröder\, Tobias Fiebig\, Martina Lindorfer\, Jürgen Cito
DESCRIPTION:[Background] Personal software configurations\, known as \emph{dotfiles}\, are increasingly being shared in public repositories. \n[Aim] To understand the security and privacy implications of this phenomenon\, we conducted a large-scale analysis of dotfiles repositories on GitHub. Furthermore\, we surveyed repository owners to understand people’s motivations for sharing dotfiles and their awareness of the security implications. \n[Method] Our mixed-method approach\, therefore\, consisted of two parts. We mined 124230 public dotfiles repositories and inductively searched them for security and privacy flaws. We then conducted a survey (n=1650) of repository owners to disclose our findings and learn more about the problems and implications. \n[Results] We found that 73.6% of repositories leak potentially sensitive information\, most commonly email addresses (of which we found 1.2 million)\, but also RSA private keys\, API keys\, installed software versions\, browsing history\, and even mail client inboxes. In addition\, we found that sharing is mainly ideological (an end in itself) and to show off (``ricing'')\, in addition to easing machine setup. Most users are confident about the contents of their files and claim to understand the security implications. In response to our disclosures\, a small minority (2.2%) will make their repositories private or delete them\, but the majority of respondents will continue sharing their dotfiles after taking appropriate actions. \n[Conclusions] Dotfiles repositories are a great tool for developers to share knowledge and communicate – if done correctly. We provide recommendations for users and platforms to make them more secure. Specifically\, tools should be used to manage dotfiles. In addition platforms should work on more sophisticated tests\, to find weaknesses automatically and inform the users or control the damage.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T033627Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T065900Z
DTEND:20230515T071100Z
DTSTAMP:20240331T110121Z
UID:0e74775f-2d9c-477f-9dcc-7d2d23ab82a5@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] MANDO-HGT: Heterogeneous Graph Transformers for Smart Contract Vulnerability Detection - Hoang H. Nguyen\, Nhat-Minh Nguyen\, Chunyao Xie\, Zahra Ahmadi\, Daniel Kudenko\, Thanh-Nam Doan\, Lingxiao Jiang
DESCRIPTION:Smart contracts in blockchains have been increasingly used for high-value business applications. It is essential to check smart contracts’ reliability before and after deployment. Although various program analysis and deep learning techniques have been proposed to detect vulnerabilities in either Ethereum smart contract source code or bytecode\, their detection accuracy and generalizability are still limited. This paper presents a novel framework named MANDO-HGT for detecting smart contract vulnerabilities. Given Ethereum smart contracts\, either in source code or bytecode form\, either vulnerable or clean\, MANDO-HGT custom-builds heterogeneous contract graphs (HCGs) to represent control-flow and/or function-call information of the code. It then adapts heterogeneous graph transformers (HGTs) with customized meta relations for graph nodes and edges to learn their embeddings and train classifiers for detecting various vulnerability types in the nodes and graphs of the contracts more accurately. We have collected more than 55K Ethereum smart contracts from various data sources and verified the labels for 423 buggy and 2\,742 clean contracts to evaluate MANDO-HGT. Our empirical results show that MANDO-HGT can significantly improve the detection accuracy of other state-of-the-art vulnerability detection techniques that are based on whether machine learning or conventional analysis techniques. The improvements in accuracy in terms of F1-score range from 0.7% to more than 76% at either the coarse-grained contract level or the fine-grained line level for various vulnerability types in either source code or bytecode. Our method is general and can be retrained easily for different vulnerability types without the need for manually defined patterns for the vulnerabilities.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T031412Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T071100Z
DTEND:20230515T071700Z
DTSTAMP:20240331T110121Z
UID:80d6807d-95dd-4ae2-8d75-5506432ed6c8@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] SecretBench: A Dataset of Software Secrets - Setu Kumar Basak\, Lorenzo Neil\, Bradley Reaves\, Laurie Williams
DESCRIPTION:According to GitGuardian’s monitoring of public GitHub repositories\, the exposure of secrets (API keys and other credentials) increased two-fold in 2021 compared to 2020\, totaling more than six million secrets. However\, no benchmark dataset is publicly available for researchers and tool developers to evaluate secret detection tools that produce many false positive warnings. The goal of our paper is to aid researchers and tool developers in evaluating and improving secret detection tools by curating a benchmark dataset of secrets through a systematic collection of secrets from open-source repositories. We present a labeled dataset of source codes containing 97\,479 secrets (of which 15\,084 are true secrets) of various secret types extracted from 818 public GitHub repositories. The dataset covers 49 programming languages and 311 file types.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230428T064428Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T080000Z
DTEND:20230515T110000Z
DTSTAMP:20240331T110121Z
UID:060ddd2d-4b2b-4f3e-b397-5470f4cde930@conf.researchr.org
CREATED:20230514T030129Z
SUMMARY:[MSR Technical Papers] MSR Dinner at Cargo Hall\, South Wharf
DESCRIPTION:
LOCATION:Offsite - , Melbourne, Australia
LAST-MODIFIED:20230514T030129Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T230000Z
DTEND:20230515T234500Z
DTSTAMP:20240331T110121Z
UID:356b5563-4f8e-46d6-9554-d9b5513128f8@conf.researchr.org
CREATED:20230426T182458Z
SUMMARY:[MSR Keynotes] Towards Code-Aware AI Models for Code - Baishakhi Ray
DESCRIPTION:The past decade has seen unprecedented growth in Software Engineering— developers spend enormous time and effort to create new products. With such enormous growth comes the responsibility of producing and maintaining quality and robust software. In this talk\, I will discuss how AI can help develop quality products in different stages of the software development life cycle. In particular\, I will discuss how we can build AI models leveraging different static and dynamic code properties for source and binary code to automate diverse Software Engineering tasks\, including code generation\, bug finding\, security analysis\, etc.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230426T182458Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T235000Z
DTEND:20230516T003000Z
DTSTAMP:20240331T110121Z
UID:814563d2-8c34-4c8c-bc9e-2205c9749177@conf.researchr.org
CREATED:20230426T175812Z
SUMMARY:[MSR Technical Papers] Tutorial: Mining and Analysing Collaboration in git Repositories with git2net - Christoph Gote
DESCRIPTION:In this 40-min tutorial\, attendees will learn how to mine fine-grained social networks from any git repository using git2net. Git repositories are used for a wide range of applications\, such as the collaboration on scientific publications and joint collections of code snippets to fully-featured coding schools and popular software projects such as Linux or Firefox. The repositories link all changes made in a set of files to their corresponding authors. In addition\, most git repositories\, e.g.\, those of Open Source software projects\, are freely accessible to researchers. Therefore\, they represent rich and accessible sources of data on social interactions. With git2net\, attendees will learn how to utilize git data for mining temporal interaction networks between authors of the repository.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230427T151304Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T235000Z
DTEND:20230515T235600Z
DTSTAMP:20240331T110121Z
UID:1808bb30-d77a-4839-bf61-7b3f3278464a@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] An Empirical Study to Investigate Collaboration Among Developers in Open Source Software (OSS) - Weijie Sun\, Samuel Iwuchukwu\, Abdul Ali Bangash\, Abram Hindle
DESCRIPTION:Project owners are realizing the benefits of teamwork\, leading to increased recognition of collaboration among developers in software engineering. A good understanding of how developers work together could positively impact software development practices. To investigate the collaboration habits of developers in project files we leverage the World of Code (WoC) dataset and GitHub API\, in this paper. We first identify the collaborations levels of developers in the project files\, such as the source\, test\, documentation\, and build files\, using the Author Cross Entropy (ACE). We find out that test files report the highest degree of collaboration among the developers\, perhaps because collaboration is critical to ensure the convergence of functionality tests. Furthermore\, the source code files show the least degree of collaboration\, perhaps because of code ownership and the complexity and difficulty in code modification. Secondly\, given the widespread usage of the Python programming language\, we investigate the Python code tokens that are more prone to change and require collaboration. Our findings offer insights into the specific project files and Python code tokens that developers typically collaborate on in the open-source community. This information can be used by researchers and developers to enhance existing collaboration platforms and tools.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230515T235600Z
DTEND:20230516T000200Z
DTSTAMP:20240331T110121Z
UID:bd50b400-bef2-4de0-8fb6-d3ed74bccbdd@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Insights into Female Contributions in Open-Source Projects - Arifa Islam Champa\, Md Fazle Rabbi\, Minhaz F. Zibran\, Md Rakibul Islam
DESCRIPTION:This paper presents a large quantitative study of the contributions of females compared to males in open-source projects. Female participation is found substantially low and females are found more engaged in non-coding work. The findings are statistically significant and are derived from an in-depth analysis of over 10 thousand developers’ contributions to more than 81 million different projects in the World of Code (WoC) infrastructure. The insights from this study are useful in addressing gender disparity in the field.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T000200Z
DTEND:20230516T000800Z
DTSTAMP:20240331T110121Z
UID:436bf00a-81d0-4b7e-ac1b-0b33b313ac40@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] The Secret Life of CVEs - Piotr Przymus\, Mikołaj Fejzer\, Jakub Narębski\, Krzysztof Stencel
DESCRIPTION:The Common Vulnerabilities and Exposures (CVEs) system is a reference method for documenting publicly known information security weaknesses and exposures. This paper presents a study of the lifetime of CVEs in software projects and the risk factors affecting their existence. The study uses survival analysis to examine how features of programming languages\, projects and CVEs themselves impact the lifetime of CVEs. We suggest avenues for future research to investigate the effect of various factors on the resolution of vulnerabilities.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T000800Z
DTEND:20230516T001400Z
DTSTAMP:20240331T110121Z
UID:55182d37-e844-40a2-971b-99d5b9d31e1f@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Evolution of the Practice of Software Testing in Java Projects - Anisha Islam\, Nipuni Tharushika Hewage\, Abdul Ali Bangash\, Abram Hindle
DESCRIPTION:Software testing helps developers minimize bugs and errors in their code\, improving the overall software quality. In 2013\, Kochhar \textit{et al.}~[1] analyzed 20\,817 software projects in order to study how prevalent the practice of software testing is in open-source projects. They found that projects with more lines of code (LOC) and projects with more developers tend to have more test cases. Additionally\, they found a weak positive correlation between the number of test cases and the number of bugs. Since the conclusions of a study might become irrelevant over time because of the latest practices in the relevant fields\, in this paper\, we investigate if these conclusions remain stable if we re-evaluate Kochhar \textit{et al.}’s findings on the Java projects that were developed from 2012 to 2021. For evaluation\, we use a random sample of 20\,000 open-source Java projects each year. Our results show that Kochhar \textit{et al.}’s conclusions regarding the LOC and the weak positive correlation between the number of test cases and bugs remain stable until 2021\, and the conclusion regarding the correlation between the number of developers with respect to the number of test cases per developer varies. Our study corroborates most of Kochhar \textit{et al.}’s findings and uncovers the slight changes in their conclusions over the years to help developers refocus in light of the latest findings regarding the practice of software testing.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T001400Z
DTEND:20230516T002000Z
DTSTAMP:20240331T110121Z
UID:842aa6a7-9667-4865-80f2-d64f3b8b4c3d@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Keep the Ball Rolling: Analyzing Release Cadence in GitHub Projects - Oz Kilic\, Nathaniel Bowness\, Olga Baysal
DESCRIPTION:Release cadence is the measure of time between software releases\, both internal and external. Few studies analyze popular open-source projects’ release cadence and use. In this work\, we gathered over 8\,000 GitHub projects from four popular programming languages\; Go\, Java\, Python\, and Ruby. Project were categorized into slow\, modern\, rapid\, and rapid+ release cadence groups. We determined that only 13% of projects had a rapid release cadence of under 30 days. Applying NLP and topic modeling\, we extracted the top 5 frequent topics for programming languages and obtained insights into their common uses. For example\, Go projects are commonly used for Kubernetes tooling\, while Ruby projects often leverage Rails for web development. We observed no significant relationship between frequent topics and the release cadence categories. This finding suggests release cadences are independent of the type of software delivered for a programming language. The replication package of our work is publicly available.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T010000Z
DTEND:20230516T011200Z
DTSTAMP:20240331T110121Z
UID:0bfd0d90-1772-4fc6-b0b1-a3dc6059e327@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Understanding the Role of Images on Stack Overflow - Dong Wang\, Tao Xiao\, Christoph Treude\, Raula Gaikovina Kula\, Hideaki Hata\, Yasutaka Kamei
DESCRIPTION:Images are increasingly being shared by software developers in diverse channels including question-and-answer forums like Stack Overflow. Although prior work has pointed out that these images are meaningful and provide complementary information compared to their associated text\, how images are used to support questions is empirically unknown. To address this knowledge gap\, in this paper we specifically conduct an empirical study to investigate (I) the characteristics of images\, (II) the extent to which images are used in different question types\, and (III) the role of images on receiving answers. Our results first show that user interface is the most common image content and undesired output is the most frequent purpose for sharing images. Moreover\, these images essentially facilitate the understanding of 68% of sampled questions. Second\, we find that discrepancy questions are more relatively frequent compared to those without images\, but there are no significant differences observed in description length in all types of questions. Third\, the quantitative results statistically validate that questions with images are more likely to receive accepted answers\, but do not speed up the time to receive answers. Our work demonstrates the crucial role that images play by approaching the topic from a new angle and lays the foundation for future opportunities to use images to assist in tasks like generating questions and identifying question-relatedness.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230524T022146Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T011200Z
DTEND:20230516T012400Z
DTSTAMP:20240331T110121Z
UID:7f3cd041-4259-4daf-adea-511a99400a2e@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Do Subjectivity and Objectivity Always Agree? A Case Study with Stack Overflow Questions - Saikat Mondal\, Masud Rahman\, Chanchal K. Roy
DESCRIPTION:In Stack Overflow (SO)\, the quality of posts (i.e.\, questions and answers) is subjectively evaluated by users through a voting mechanism. The net votes (upvotes - downvotes) obtained by a post are often considered an approximation of its quality. However\, about half of the questions that received working solutions got more downvotes than upvotes. Furthermore\, about 18% of the accepted answers (i.e.\, verified solutions) also do not score the maximum votes. All these counter-intuitive findings cast doubts on the reliability of the evaluation mechanism employed at SO. Moreover\, many users raise concerns against the evaluation\, especially downvotes to their posts. Therefore\, rigorous verification of the subjective evaluation is highly warranted to ensure a non-biased and reliable quality assessment mechanism. In this article\, we compare the subjective assessment of questions with their objective assessment using 2.5 million questions and ten text analysis metrics. According to our investigation\, (1) four objective metrics agree\, (2) two metrics do not agree\, (3) one metric either agrees or disagrees\, and (4) the remaining three metrics neither agree nor disagree with the subjective evaluation. We then develop machine learning models to classify the promoted and discouraged questions. Our models outperform the state-of-the-art models with a maximum of about 76%–87% accuracy.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T012400Z
DTEND:20230516T013000Z
DTSTAMP:20240331T110121Z
UID:f5eff7ff-111f-4c51-8ce8-fcf07b66fd02@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] GiveMeLabeledIssues: An Open Source Issue Recommendation System - Joseph Vargovich\, Fabio Marcos De Abreu Santos\, Jacob Penney\, Marco Gerosa\, Igor Steinmacher
DESCRIPTION:Developers often struggle to identify the skills required to work on open issues in Open Source Software (OSS) projects. Proper issue labeling can help task selection\, but current strategies are limited to classifying the issues according to their type (e.g.\, bug\, question\, good first issue\, feature\, etc.). In contrast\, this paper presents a tool that mines project repositories and labels issues based on the skills required to solve them\, more specifically the domain of the APIs involved in the solution (e.g.\, User Interface (UI)\, Test\, Databases (DB)\, etc.). GiveMeLabeledIssues facilitates matching developers’ skills and tasks\, reducing the burden on project maintainers by minimizing the amount of manual labeling needed to annotate project issues effectively. The demo toll obtained a precision of 83.9% predicting projects with TF-IDF and Random Forest (RF).
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T013000Z
DTEND:20230516T013600Z
DTSTAMP:20240331T110121Z
UID:f9e441fe-d161-47d1-84fe-0b434e67267f@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] DocMine: A Software Documentation-Related Dataset of 950 GitHub Repositories - Akhila Sri Manasa Venigalla\, Sridhar Chimalakonda
DESCRIPTION:Software documentation is one of the critical aspects of a software project\, that could support multiple tasks throughout the software development life-cycle. There is extensive research on understanding issues and challenges with existing documentation\, which is typically available as readme files. In projects that support collaborative development\, such as those on GitHub\, other software artifacts such as commits\, pull requests and issues\, apart from the conventional readme files\, wikis and source code comments\, also contain useful information\, that supports in understanding\, using\, extending and maintaining the project. However\, we are not aware of any dataset that explicitly focuses on documentation-related information in multiple software artifacts such as readme files\, commits and pull requests across a repository. To address this concern and to facilitate further research in software documentation\, we present DocMine\, as a dataset of documentation-related information\, extracted from around 1.35M software artifacts in 950 GitHub repositories\, spanning across four different programming languages. The dataset along with its documentation is made available in CSV and .sql formats at - https://doi.org/10.5281/zenodo.5195084.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T013600Z
DTEND:20230516T014200Z
DTSTAMP:20240331T110121Z
UID:91aeb4cc-e604-4ec0-8861-dfe8c4b44ffe@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] PENTACET data - 23 Million Code Comments and 500\,000 SATD comments - Murali Sridharan\, Leevi Rantala\, Mika Mäntylä
DESCRIPTION:Most SATD research utilizes non-probabilistic sampling for data selection\, which weakens the empirical findings’ generalization capability. A closer look reveals several SATD research are based on simple (`Easy to find’) code comments without the contextual data (preceding and succeeding source code context). In this work\, we address this gap through PENTACET (or 5C) dataset. PENTACET is a large Curated Contextual Code Comments per Contributor and the most extensive SATD data. It is acquired by mining 9\,096 Open Source Software Java projects with a total of 435 million LOC and captures bi-directional contextual information of all source code granularities in more than 26 million source code files. The outcome is data set with 23 million code comments\, source code context for each comment\, and more than 500\,000 comments labeled as SATD.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T010000Z
DTEND:20230516T011200Z
DTSTAMP:20240331T110121Z
UID:2585b375-ec63-4b13-9ed4-6efa8935acce@conf.researchr.org
CREATED:20230515T031450Z
SUMMARY:[MSR Technical Papers] Don't Forget the Exception! Considering Robustness Changes to Identify Design Problems - Anderson Oliveira\, João Lucas Correia\, Leonardo Da Silva Sousa\, Wesley Assunção\, Daniel Coutinho\, Alessandro Garcia\, Willian Oizumi\, Caio Barbosa\, Anderson Uchôa\, Juliana Alves Pereira
DESCRIPTION:Modern programming languages\, such as Java\, use exception-handling mechanisms to guarantee the robustness of software systems. Although important\, the quality of exception code is usually poor and neglected by developers. Indiscriminate robustness changes (e.g.\, the addition of empty catch blocks) can indicate design decisions that negatively impact the internal quality of software systems. As it is known in the literature\, multiple occurrences of poor code structures\, namely code smells\, are strong indicators of design problems. Still\, existing studies focus mainly on the correlation of maintainability smells with design problems. However\, using only these smells may not be enough since developers need more context (e.g.\, system domain) to identify the problems in certain scenarios. Moreover\, these studies do not explore how changes in the exceptional code of the methods combined with maintainability smells can give complementary evidence of design problems. By covering both regular and exception codes\, the developer can have more context about the system and find complementary code smells that reinforce the presence of design problems. This work aims to leverage the identification of design problems by tracking poor robustness changes combined with maintainability smells. We investigated the correlation between robustness changes and maintainability smells on the commit history of more than 160k methods from different releases of 10 open-source software systems. We observed that maintainability smells can be worsened or even introduced when robustness changes are performed. This scenario mainly happened for the Feature Envy\, Long Method\, and Dispersed Coupling smells. We also analyzed the co-occurrence between robustness and maintainability smells. We identified that the empty catch block and catch throwable robustness smells were the ones that co-occurred the most with maintainability smells related to the Concern Overload and Misplaced Concern design problems. The contribution of our work is to reveal that poor exception code\, usually neglected by developers\, negatively impacts the overall quality of software systems. Therefore\, existing code smell detecting tools can be enhanced to leverage robustness changes to identify design problems.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230516T014815Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T011200Z
DTEND:20230516T012400Z
DTSTAMP:20240331T110121Z
UID:2bdf5bd3-72d5-474e-bad8-ea70d0589bb9@conf.researchr.org
CREATED:20230515T031450Z
SUMMARY:[MSR Technical Papers] Pre-trained Model Based Feature Envy Detection - mawenhao \, Yaoxiang Yu\, Xiaoming Ruan\, Bo Cai
DESCRIPTION:Code smell slows down software system development and makes them harder to maintain. Existing research aims to develop automatic detection algorithms to reduce the labor and time costs within the detection process. Deep learning techniques have recently been demonstrated to enhance the performance of recognizing code smell even more than metric-based heuristic detection algorithms. As Large-scale pre-trained models for Programming Languages (PL)\, such as CodeT5\, have lately achieved the top results in a variety of downstream tasks\, some researchers begin to explore the use of pre-trained models to extract the contextual semantics of code to detect code smells. However\, little research has employed contextual code semantics relationship between code snippets obtained by pre-trained models to identify code smells. In this paper\, we investigate the use of the pre-trained model codeT5 to extract semantic relationships between code snippets to detect feature envy\, which is one of the most common code smells. In addition\, to investigate the performance of these semantic relationships extracted by pre-trained models of different architectures on detecting feature envy\, we compare CodeT5 with two other pre-trained models CodeBert\, CodeGPT. % We have performed our experimental evaluation on ten open-source projects\, our approach outperforms the state-of-the-art in F-measure with a 29.32% improvement on detecting feature envy and in accuracy with a 16.57% improvement on moving destination recommendation. We have performed our experimental evaluation on ten open-source projects\, our approach improves F-measure by 29.32% on feature envy detection and 16.57% on moving destination recommendation. And using semantic relations extracted by several pre-trained models to detect feature envy outperforms the state-of-the-art. This shows that using this semantic relation to detect feature envy is promising. To enable future research on feature envy detection\, we have made all the code and datasets utilized in this article open source.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T043435Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T012400Z
DTEND:20230516T013000Z
DTSTAMP:20240331T110121Z
UID:fc4f8a06-6103-44ff-b89d-3184bd54087e@conf.researchr.org
CREATED:20230515T031450Z
SUMMARY:[MSR Technical Papers] CLEAN++: Code Smells Extraction for C++ - Tom Mashiach\, Bruno Sotto-Mayor\, Gal Kaminka\, Meir Kalech
DESCRIPTION:The extraction of features is an essential step in the process of mining software repositories. An important feature that has been actively studied in the field of mining software repositories is bad code smells. Bad code smells are patterns in the source code that indicate an underlying issue in the design and implementation of the software. Several tools have been proposed to extract code smells. However\, currently there are no tools that extract a significant number of code smells from software written in C++. Therefore\, we propose CLEAN++ (Code smeLls ExtrActioN for c++). It is an extension of a robust static code analysis tool that implements 35 code smells. To evaluate CLEAN++\, we ran it over 44 open-source projects and wrote test cases to validate each code smell. Also\, we converted the test cases to Java and used two Java tools to validate the effectiveness of our tool. In the end\, we confirmed that the CLEAN++ is successful at detecting code smells. The tool is available at https://github.com/Tomma94/CLEAN-Plus-Plus.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T043510Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T013000Z
DTEND:20230516T013600Z
DTSTAMP:20240331T110121Z
UID:97964b01-a271-4996-a35e-d7bc9da0e64b@conf.researchr.org
CREATED:20230515T031450Z
SUMMARY:[MSR Technical Papers] DACOS-A Manually Annotated Dataset of Code Smells - Himesh Nandani\, Mootez Saad\, Tushar Sharma
DESCRIPTION:Researchers apply machine-learning techniques for code smell detection to counter the subjectivity of many code smells. Such approaches need a large\, manually annotated dataset for training and benchmarking. Existing literature offers a few datasets\; however\, they are small in size and\, more importantly\, do not focus on the subjective code snippets. In this paper\, we present DACOS\, a manually annotated dataset containing 10\,267 annotations for 5\,192 code snippets. The dataset targets three kinds of code smells at different granularity-multifaceted abstraction\, complex method\, and long parameter list. The dataset is created in two phases. The first phase helps us identify the code snippets that are potentially subjective by determining the thresholds of metrics used to detect a smell. The second phase collects annotations for potentially subjective snippets. We also offer an extended dataset DACOSX that includes definitely benign and definitely smelly snippets by using the thresholds identified in the first phase. We have developed Tagman\, a web application to help annotators view and mark the snippets one-by-one and record the provided annotations. We make the datasets and the web application accessible publicly. This dataset will help researchers working on smell detection techniques to build relevant and context-aware machine-learning models.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T231846Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T013600Z
DTEND:20230516T014200Z
DTSTAMP:20240331T110121Z
UID:8af02603-4d08-4bf4-a8f2-ea9e4657b2bf@conf.researchr.org
CREATED:20230515T031450Z
SUMMARY:[MSR Technical Papers] What Warnings Do Engineers Really Fix? The Compiler That Cried Wolf - Gunnar Kudrjavets\, Aditya Kumar\, Ayushi Rastogi
DESCRIPTION:Build logs from a variety of Continuous Integration (CI) systems contain temporal data about the presence and distribution of compiler warnings. Results from the analysis and mining of that data will indicate what warnings engineers find useful and fix\, or continuously ignore. The findings will include resolution times and resolution types for different warning categories. That data will help compiler developers adjust the warning levels according to the ground truth\, clarify the diagnostic messages\, and improve the non-actionable warnings. The empirical findings will also help engineers to decide what warnings are worth fixing and which ones are not.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T043659Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T015000Z
DTEND:20230516T020200Z
DTSTAMP:20240331T110121Z
UID:770ff8ab-385a-4471-aa7e-509750201444@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Automating Arduino Programming: From Hardware Setups to Sample Source Code Generation - Imam Nur Bani Yusuf\, Diyanah Binte Abdul Jamal\, Lingxiao Jiang
DESCRIPTION:An embedded system is a system consisting of software code\, controller hardware\, and Input/Output hardware that performs a specific task. There are several challenges when developing an embedded system. First\, the code often involves hardware configurations that require domain-specific knowledge. Second\, the hardware may have code usage patterns that should be followed. To overcome such challenges\, we propose a framework called ArduinoProg towards automatic generation of Arduino applications. ArduinoProg takes natural language queries as input\, then outputs hardware configurations and code usage patterns of the hardware for the query. Motivated by our findings on the characteristics of real-world queries posted in the official Arduino forum\, we formulate ArduinoProg as three components\, i.e.\, Library Retriever\, Hardware Classifier\, and API Generator. First\, Library Retriever preprocesses the input query and retrieves a set of relevant library names using either lexical matching or vector-based similarity. Second\, given Library Retriever’s output\, Hardware Classifier infers the hardware configuration by classifying the method definitions from the implementation files of a library into certain communication protocol classes. Third\, API Generator leverages a sequence-to-sequence model to generate the code usage patterns also based on the Library Retriever’s output. Having instantiated each component of ArduinoProg with various machine learning models\, we have evaluated ArduinoProg on real-world queries. The performance of Library Retriever ranges from 44.0%-97.1% in terms of Precision@K\; the Hardware Classifier classifier can achieve 0.79-0.92 in terms of the area under the Receiver Operating Characteristics curve (AUC)\; API Generator can yield 0.45-0.73 in terms of Normalized Discounted Cumulative Gain (NDCG)@K. Demo: https://youtu.be/d8E4Zjrs_KQ
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230516T002430Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T020200Z
DTEND:20230516T020800Z
DTSTAMP:20240331T110121Z
UID:2f7994eb-5aa4-4beb-bd9f-5b1341e25b50@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] A Dataset of Bot and Human Activities in GitHub - Natarajan Chidambaram\, Alexandre Decan \, Tom Mens
DESCRIPTION:Software repositories hosted on GitHub frequently use development bots to automate repetitive\, effort-intensive and error-prone tasks. To understand and study how these bots are used\, state-of-the-art bot identification tools have been developed to detect bots based on their comments in commits\, issues and pull requests. Given that bots can be involved in many other activity types\, there is a need to consider more activities that they are carrying out in the software repositories they are involved in. We\, therefore\, propose a curated dataset of such activities carried out by bots and humans involved in GitHub repositories. The dataset was constructed by identifying 24 high-level activity types that could be extracted from 15 lower-level GitHub event types that were queried from GitHub’s event stream API for all considered bots and humans. The proposed dataset contains around 600K activities performed by 384 bots and 585 humans involved in GitHub repositories\, during an observation period ranging from 25 November 2022 to 25 January 2023. This dataset is valuable for future empirical studies focusing on how bots impact the software development process.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T190622Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T020800Z
DTEND:20230516T021400Z
DTSTAMP:20240331T110121Z
UID:8a1b7dca-446e-48f6-9c0f-dfebf97bb475@conf.researchr.org
CREATED:20230502T180824Z
SUMMARY:[MSR Technical Papers] Mining the Characteristics of Jupyter Notebooks in Data Science Projects - Morakot Choetkiertikul\, Apirak Hoonlor\, Chaiyong Ragkhitwetsagul\, Siripen Pongpaichet\, Thanwadee Sunetnanta\, Tasha Settewong\, Raula Gaikovina Kula
DESCRIPTION:Nowadays\, numerous industries have exceptional demand for skills in data science\, such as data analysis\, data mining\, and machine learning. The computational notebook (e.g.\, Jupyter notebook) is a well-known data science tool adopted in practice. Kaggle and GitHub are two platforms where data science communities are used for knowledge-sharing\, skill-practicing\, and collaboration. While tutorials and guidelines for novice data science are available on both platforms\, there is a low number of Jupyter notebooks that received high numbers of votes from the community. The high-voted notebook is considered well-documented\, easy to understand\, and applies the best data science and software engineering practices. In this research\, we aim to understand the characteristics of high-voted Jupyter notebooks on Kaggle and the popular Jupyter notebooks for data science projects on GitHub. We plan to mine and analyze the Jupyter notebooks on both platforms. We will perform exploratory analytics\, data visualization\, and feature importances to understand the overall structure of these notebooks and to identify common patterns and best-practice features separating the low-voted and high-voted notebooks. Upon the completion of this research\, the discovered insights can be applied as training guidelines for aspiring data scientists and machine learning practitioners looking to improve their performance from novice ranking Jupyter notebook on Kaggle to a deployable project on GitHub.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T233058Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T021400Z
DTEND:20230516T022000Z
DTSTAMP:20240331T110121Z
UID:31868790-6059-4db5-b7f2-d20ec40f4494@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Optimizing Duplicate Size Thresholds in IDEs - Konstantin Grotov\, Sergey Titov\, Alexandr Suhinin\, Yaroslav Golubev\, Timofey Bryksin
DESCRIPTION:In this paper\, we present an approach for transferring an optimal lower size threshold for clone detection from one language to another by analyzing their clone distributions. We showcase this method by transferring the threshold from regular Python scripts to Jupyter notebooks for using in two JetBrains IDEs\, Datalore and DataSpell.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T190623Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T022000Z
DTEND:20230516T023200Z
DTSTAMP:20240331T110121Z
UID:75ad69fc-7844-4c09-b1bb-570a96fcae30@conf.researchr.org
CREATED:20230502T184650Z
SUMMARY:[MSR Technical Papers] Boosting Just-in-Time Defect Prediction with Specific Features of C Programming Languages in Code Changes - Chao Ni\, xiaodanxu \, Kaiwen Yang\, David Lo
DESCRIPTION:Just-in-time (JIT) defect prediction can identify changes as defect-inducing ones or clean ones and many approaches are proposed based on several programming language-independent change-level features. However\, different programming languages have different characteristics and consequently may affect the quality of software projects. Meanwhile\, the C programming language\, one of the most popular ones\, is widely used to develop foundation applications (i.e.\, operating system\, database\, compiler\, etc.) in IT companies and its change-level characteristics on project quality have not been fully investigated. Additionally\, whether open-source C projects have similar important features to commercial projects has not been studied much. \nTo address the aforementioned limitations\, in this paper\, we investigate the impacts of programming language-specific features on the state-of-the-art JIT defect identification approach in an industrial setting. We collect and label the top-10 most starred C projects (i.e.\, 329\,021 commits) on GitHub and 8 C projects in an ICT company (i.e.\, 12\,983 commits). We also propose nine C-specific change-level features and focus our investigations on both open-source C projects on GitHub and C projects at the ICT company considering three aspects: (1) The effectiveness of C-specific change-level features in improving the performance of identification of defect-inducing changes\, (2) The importance of features in the identification of defect-inducing changes between open-source C projects and commercial C projects\, and (3) The effectiveness of combining language-independent features and C-specific features in a real-life setting at the ICT company.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230502T190624Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T015000Z
DTEND:20230516T020200Z
DTSTAMP:20240331T110121Z
UID:75e8eef2-d86d-4213-9129-376fcb8a56b2@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] A Large Scale Analysis of Semantic Versioning in NPM - Donald Pinckney\, Federico Cassano\, Arjun Guha\, Jonathan Bell
DESCRIPTION:The NPM package repository contains over two million packages and serves tens of billions of downloads per-week. Nearly every single JavaScript application uses the NPM package manager to install packages from the NPM repository. NPM relies on a “semantic versioning” (‘semver’) scheme to maintain a healthy ecosystem\, where bug-fixes are reliably delivered to downstream packages as quickly as possible\, while breaking changes require manual intervention by downstream package maintainers. In order to understand how developers use semver\, we build a dataset containing every version of every package on NPM and analyze the flow of updates throughout the ecosystem. We build a time-travelling dependency resolver for NPM\, which allows us to determine precisely which versions of each dependency would have been resolved at different times. We segment our analysis to allow for a direct analysis of security-relevant updates (those that introduce or patch vulnerabilities) in comparison to the rest of the ecosystem. We find that when developers use semver correctly\, critical updates such as security patches can flow quite rapidly to downstream dependencies in the majority of cases (90.09%)\, but this does not always occur\, due to developers’ imperfect use of both semver version constraints and semver version number increments. Our findings have implications for developers and researchers alike. We make our infrastructure and dataset publicly available under an open source license.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230515T084804Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T020200Z
DTEND:20230516T021400Z
DTSTAMP:20240331T110121Z
UID:84dd97c8-7e2b-4105-b116-32e26d55ed65@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Phylogenetic Analysis of Reticulate Software Evolution - Akira Mori\, Masatomo Hashimoto
DESCRIPTION:In this paper\, we apply techniques from phylogenetics for uncovering evolutionary dependencies among software versions. Phylogenetics is a part of computational molecular biology that addresses the in ference of evolution among organisms based on differences/similarities in DNA sequences and morphology. We apply a tree differencing technique to abstract syntax trees to calculate a distance matrix\, which is then used by a distance-based phylogenetic algorithm to infer an evolution network. This allows us to identify merging and branching among versions without manually looking into the details of the source code. Experiments on ancient/old versions of the Emacs editor and the open source 3D printer firmware show that we not only can reproduce the evolution of the software but also can identify code import/merging across different lineages. We also discuss how the techniques are used to identify the feature models among software variations. To the best of our knowledge\, this paper is the first to report on a reticulate phylogenetic analysis of the software and may offer a useful method for gaining information on the evolution of the software.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T021400Z
DTEND:20230516T022000Z
DTSTAMP:20240331T110121Z
UID:9cff438e-acc0-4c63-ae40-2e6a42910289@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] PyMigBench: A Benchmark for Python Library Migration - Mohayeminul Islam\, Ajay Jha\, Sarah Nadi\, Ildar Akhmetov
DESCRIPTION:Developers heavily rely on Application Programming Interfaces (APIs) from libraries to build their projects. However\, libraries might become obsolete\, or new libraries with better APIs might become available. In such cases\, developers replace the used libraries with alternative libraries\, a process known as library migration. Since manually migrating between libraries is tedious and error prone\, there has been a lot of effort towards automated library migration. However\, most of the current research on automated library migration focuses on Java libraries\, and even more so on version migrations of the same library. Despite the increasing popularity of Python\, limited research has investigated migration between Python libraries. To provide the necessary data for advancing the development of Python library migration tools\, this paper contributes PyMigBench\, a benchmark of real Python library migrations. PyMigBench contains 59 analogous library pairs and 75 real migrations with migration-related code changes in 160 Python files across 57 client repositories.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230428T004503Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T022000Z
DTEND:20230516T022600Z
DTSTAMP:20240331T110121Z
UID:6045e10b-7c44-4006-bacf-fc8d41bd91a3@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Determining Open Source Project Boundaries - Sophia Vargas
DESCRIPTION:This talk proposal discusses the challenge of determining the boundaries of an open source software project. While open source ecosystems have fluid membership by nature\, explicit boundaries are necessary to conduct research and analysis around projects and their communities as these exercises must select a set number of repositories\, forums\, mailing lists\, etc to count as part of this effort. The ideal solution to this problem would provide researchers and analysts with a common approach to identify what is part of or affiliated with a project community and ecosystem.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T022600Z
DTEND:20230516T023200Z
DTSTAMP:20240331T110121Z
UID:2587268f-0f57-470e-b661-bed6049b78d1@conf.researchr.org
CREATED:20230426T151508Z
SUMMARY:[MSR Technical Papers] Intertwining Communities: Exploring Libraries that Cross Software Ecosystems - Kanchanok Kannee\, Raula Gaikovina Kula\, Supatsara Wattanakriengkrai\, Kenichi Matsumoto
DESCRIPTION:Using libraries in applications have helped developers to reduce the costs of reinventing already existing code. However\, an increase in diverse technology stacks and third-party library usage has led developers to inevitably switch technologies\, and also search for similar libraries implemented in the new technology. To assist with searching for these replacement libraries\, maintainers have started to release their libraries to multiple ecosystems. Our goal is to explore the extent to which these libraries are intertwined between ecosystems. We perform a large-scale empirical study of 1.1 million libraries from five different software ecosystems\, i.e.\, PyPI\, CRAN\, Maven\, RubyGems\, and NPM\, to identify 4\,146 GitHub repositories. As a starting point\, insights from the study raise implications for library maintainers\, users\, contributors\, and researchers into understanding how these different ecosystems are becoming more intertwined with each other.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151508Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T034500Z
DTEND:20230516T043000Z
DTSTAMP:20240331T110121Z
UID:c08f691f-23f8-4206-9555-c29d46f5d388@conf.researchr.org
CREATED:20230515T031342Z
SUMMARY:[MSR Technical Papers] Tutorial: Beyond the leading edge. What else is out there? - Tim Menzies
DESCRIPTION:Predictions are often wrong\, especially about the future. But if we were to take a bet on the future\, what technologies might we see? LLM\, deep learning\, sure\, but what ELSE is out there? This talk will focus on three leading edge and three bleeding edge trends: \n \n  leading edge = data mining\, optimization\, theorem proving  \n  bleeding edge = fairness\, semi-supervised learning\, knowledge curation  \n \nCome along or be oblong!
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T143442Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T034500Z
DTEND:20230516T035700Z
DTSTAMP:20240331T110121Z
UID:47c94d0f-5c56-4729-83a6-8611c36a9f4e@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] Helm Charts for Kubernetes Applications: Evolution\, Outdatedness and Security Risks - Ahmed Zerouali\, Ruben Opdebeeck\, Coen De Roover
DESCRIPTION:Using Kubernetes for the deployment\, management and scaling of containerized applications has become a common practice. To facilitate the installation and management of these applications on Kubernetes clusters\, practitioners can use the Helm package manager. Helm enables defining\, installing and upgrade complex Kubernetes applications in an easy and organized way through Charts. Our goal is to support chart developers and users by assessing the state and evolution of publicly available charts\, as well as the outdatedness and security risks of their images. For 9\,482 charts that are distributed via the Artifact Hub repository\, we mine and collect the list of their metadata\, versions\, dependencies\, maintainers and container images. Then\, we carry out an empirical analysis into seven aspects. We found that the ecosystem forming around Helm Charts ecosystem is growing fast. However\, most of the Charts are not official with no popularity and no license. We also observed that charts tend to release multiple versions\, but around half of them are still in the initial development phase. When looking at the container images used in charts\, we found that around half of them are outdated and 88.1% of them are exposed to vulnerabilities\, jeopardizing 93.7% of the charts.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T035700Z
DTEND:20230516T040900Z
DTSTAMP:20240331T110121Z
UID:ff3f51aa-f801-44dc-96c3-c7bcc197fe05@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] Control and Data Flow in Security Smell Detection for Infrastructure as Code: Is It Worth the Effort? - Ruben Opdebeeck\, Ahmed Zerouali\, Coen De Roover
DESCRIPTION:Infrastructure as Code is the practice of developing and maintaining computing infrastructure through executable source code. Unfortunately\, IaC has also brought about new cyber attack vectors. Prior work has therefore proposed static analyses that detect security smells in Infrastructure as Code files. However\, they have so far remained at a shallow level\, disregarding the control and data flow of the scripts under analysis\, and may lack awareness of specific syntactic constructs. These limitations inhibit the quality of their results. To address these limitations\, in this paper\, we present GASEL\, a novel security smell detector for the Ansible IaC language. It uses graph queries on program dependence graphs to detect 7 security smells. Our evaluation on an oracle of 243 real-world security smells and comparison against two state-of-the-art security smell detectors shows that awareness of syntax\, control flow\, and data flow enables our approach to substantially improve both precision and recall. We further question whether the additional effort required to develop and run such an approach is justified in practice. To this end\, we investigate the prevalence of indirection through control and data flow in security smells across more than 15 000 Ansible scripts. We find that over 55% of security smells contain data-flow indirection\, and over 32% require a whole-project analysis to detect. These findings motivate the need for deeper static analysis tools to detect security vulnerabilities in IaC.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T040900Z
DTEND:20230516T042100Z
DTSTAMP:20240331T110121Z
UID:e94c263d-1dc4-4889-8dac-ce99b41a21ea@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] Method Chaining Redux: An Empirical Study of Method Chaining in Java\, Kotlin\, and Python - Ali Keshk\, Robert Dyer
DESCRIPTION:There are possible benefits and drawbacks to chaining methods together\, as is often done in fluent APIs. A prior study investigated how Java developers chain methods in over 2.7k open-source projects. That study observed\, for the dataset analyzed\, that the use of method chaining in Java is popular and seems to be increasing over time. That study however was limited to a smaller sample of Java projects\, and it is also not clear if the results generalize to other languages. In this work\, we first replicate the prior results by building a similar dataset and our own analysis scripts. We then extend those results by analyzing a much larger dataset of 89k Java projects and generalizing to other programming languages by analyzing 26k Kotlin projects and 98k Python projects. The results show chaining is more popular in Java and Kotlin than Python\, chaining use in Kotlin is not growing\, and Python sees more use in non-testing code.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T042100Z
DTEND:20230516T042700Z
DTSTAMP:20240331T110121Z
UID:42b09742-4197-4db5-8422-5a783b52c727@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] Snapshot Testing Dataset - Emily Bui\, Henrique Rocha
DESCRIPTION:Snapshot testing is a form of software testing that is focused on visual components by highlighting any code changes when compared to a previously stored state. This quick and simple method of testing is growing popular among the industry with companies such as Spotify and Robinhood. Despite its growing popularity\, snapshot testing is barely explored in academia. In this paper\, we use GitHub API to collect a dataset of 686 repositories tagged with Jest\, a popular testing framework capable of snapshot testing. From those repositories\, we found 4\,604 snapshot files and 11\,367 test files. The top-10 repositories represent 20% of all snapshot files in the dataset\, even though it is only 3% of the size. We acknowledge that improvements can be made in the dataset but due to the lack of data on snapshot testing\, we believe the current dataset is useful in helping researchers to study this topic.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T043500Z
DTEND:20230516T044700Z
DTSTAMP:20240331T110121Z
UID:d55a00d4-6236-495e-98fe-183673444a9c@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] Large Language Models and Simple\, Stupid Bugs - Kevin Jesse\, Toufique Ahmed\, Prem Devanbu\, Emily Morgan
DESCRIPTION:With the advent of powerful neural language models\, AI-based systems to assist developers in coding tasks are becoming widely available\; Copilot is one such system. Copilot uses Codex\, a large language model (LLM)\, to complete code conditioned on a preceding “prompt”. Codex\, however\, is trained on public GitHub repositories\, viz.\, on code that may include bugs and vulnerabilities. Previous studies [1]\, [2] show Codex reproduces vulnerabilities seen in training. In this study\, we examine how prone Codex is to generate an interesting bug category\, single statement bugs\, commonly referred to as simple\, stupid bugs or SStuBs in the MSR community. We find that Codex and similar LLMs do help avoid some SStuBs\, but do produce known\, verbatim SStuBs as much as 2x as likely than known\, verbatim correct code. We explore the consequences of the Codex generated SStuBs and propose avoidance strategies that suggest the possibility of reducing the production of known\, verbatim SStubs\, and increase the possibility of producing known\, verbatim fixes.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T044700Z
DTEND:20230516T045900Z
DTSTAMP:20240331T110121Z
UID:d74ebe23-1c32-4233-a9a5-6832adab5c40@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] The ABLoTS Approach for Bug Localization: is it replicable and generalizable? - Feifei Niu\, Christoph Mayr-Dorn\, Wesley Assunção\, Liguo Huang\, Jidong Ge\, Bin Luo\, Alexander Egyed
DESCRIPTION:Bug localization is the task of recommending source code locations (typically files) that probably contain the cause of a bug and hence need to be changed to fix the bug. Along these lines\, information retrieval-based bug localization (IRBL) approaches have been adopted\, which identify the most bug-prone files from the source code space. In current practice\, a series of state-of-the-art IRBL techniques leverage the combination of different components\, e.g.\, similar reports\, version history\, code structure\, to achieve better performance. ABLoTS is a recently proposed approach with the core component\, TraceScore that utilizes requirements and traceability information between different issue reports (i.e.\, feature requests and bug reports) to identify buggy source code snippets with promising results. To evaluate the accuracy of these results and obtain additional insights into the practical applicability of ABLoTS\, in supporting of future more efficient and rapid replication and comparison\, we conducted a replication study of this approach with the original data set and also on an extended data set. The extended data set includes 16 more projects comprising 25\,893 bug reports and corresponding source code commits. While we find that the TraceScore component as the core of ABLoTS produces comparable results with the extended data set\, we also find that the ABLoTS approach no longer achieves promising results due to an overlooked side-effect of incorrectly choosing a cut-off date that led to training data leaking into test data with significant effects on performance.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230515T024228Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T045900Z
DTEND:20230516T050500Z
DTSTAMP:20240331T110121Z
UID:0cabd41f-01a2-4907-871d-01d4363bf3ac@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations - Catherine Tony\, Markus Mutas\, Nicolás E. Díaz Ferreyra\, Riccardo Scandariato
DESCRIPTION:Large Language Models (LLMs) like Codex are powerful tools for performing code completion and code generation tasks as they are trained on billions of lines of code from publicly available sources. Moreover\, these models are capable of generating code snippets from Natural Language (NL) descriptions by learning languages and programming practices from public GitHub repositories. Although LLMs promise an effortless NL-driven deployment of software applications\, the security of the code they generate has not been extensively investigated nor documented. In this work\, we present \textit{LLMSecEval}\, a dataset containing 150 NL prompts that can be leveraged for assessing the security performance of such models. Such prompts are NL descriptions of code snippets prone to various security vulnerabilities listed in MITRE’s top 25 Common Weakness Enumeration (CWE) ranking. Each prompt in our dataset comes with a secure implementation example to facilitate comparative evaluations against code produced by LLMs. As a practical application\, we show how \textit{LLMSecEval} can be used for evaluating the security of snippets automatically generated from NL descriptions.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T050500Z
DTEND:20230516T051100Z
DTSTAMP:20240331T110121Z
UID:0b2310f2-d770-4139-b5cf-54052c61e876@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] Defectors: A Large\, Diverse Python Dataset for Defect Prediction - Parvez Mahbub\, Ohiduzzaman Shuvo\, Masud Rahman
DESCRIPTION:Defect prediction has been a popular research topic where deep learning has found numerous applications. However\, these deep learning-based defect prediction models are often limited by the quality and size of their datasets. In this paper\, we present Defectors\, a large dataset for just-in-time and line-level defect prediction. Defectors consists of $\approx$ 213K source code files ($\approx$ 93K defective and $\approx$ 120K defect-free) that span across 24 popular Python projects. These projects come from 18 different domains\, including machine learning\, automation\, and internet-of-things. Such a scale and diversity make Defectors a suitable dataset for training deep learning models\, especially transformer models that require large and diverse datasets. We also foresee several application areas of our dataset including defect prediction\, defect explanation\, and automated program repair.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T043500Z
DTEND:20230516T044700Z
DTSTAMP:20240331T110121Z
UID:ee32f38d-f041-4a35-9365-4df3612e2a11@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] A Study of Gender Discussions in Mobile Apps - Mojtaba Shahin\, Mansooreh Zahedi\, Hourieh Khalajzadeh\, Ali Rezaei Nasab
DESCRIPTION:Mobile software apps (“apps”) are one of the prevailing digital technologies that our modern life heavily depends on. A key issue in the development of apps is how to design gender-inclusive apps. Apps that do not consider gender inclusion\, diversity\, and equality in their design can create barriers (e.g.\, excluding some of the users because of their gender) for their diverse users. While there have been some efforts to develop gender-inclusive apps\, a lack of deep understanding regarding user perspectives on gender may prevent app developers and owners from identifying issues related to gender and proposing solutions for improvement. Users express many different opinions about apps in their reviews\, from sharing their experiences\, and reporting bugs\, to requesting new features. In this study\, we aim at unpacking gender discussions about apps from the user perspective by analysing app reviews. We first develop and evaluate several Machine Learning (ML) and Deep Learning (DL) classifiers that automatically detect gender reviews (i.e.\, reviews that contain discussions about gender). We apply our ML and DL classifiers on a manually constructed dataset of 1\,440 app reviews from the Google App Store\, composing 620 gender reviews and 820 non-gender reviews. Our best classifier achieves an F1-score of 90.77%. Second\, our qualitative analysis of a randomly selected 388 out of 620 gender reviews shows that gender discussions in app reviews revolve around six topics: App Features\, Appearance\, Content\, Company Policy and Censorship\, Advertisement\, and Community. Finally\, we provide some practical implications and recommendations for developing gender-inclusive apps.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T044700Z
DTEND:20230516T045900Z
DTSTAMP:20240331T110121Z
UID:061fc606-08a9-4ffc-a62d-98b08b7c990b@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] Tell Me Who Are You Talking to and I Will Tell You What Issues Need Your Skills - Fabio Marcos De Abreu Santos\, Jacob Penney\, João Felipe Pimentel\, Igor Wiese\, Igor Steinmacher\, Marco Gerosa
DESCRIPTION:Abstract— Selecting an appropriate task is a challenging step for newcomers to Open Source Software (OSS) projects. To facilitate task selection\, researchers and OSS projects have leveraged machine learning techniques\, historical information\, and textual analysis to label tasks (a.k.a. issues) with information such as the issue type and domain. These approaches are still far from mainstream adoption\, possibly because of a lack of good predictors. Inspired by previous research\, we advocate that label prediction might benefit from leveraging metrics derived from communication data and social network analysis (SNA) for issues in which social interaction occurs. Thus\, we study how these “social metrics” can improve the automatic labeling of open issues with API domains—categories of APIs used in the source code that solves the issue—which the literature shows that newcomers to the project consider relevant for task selection. We mined data from OSS projects’ repositories and organized it in periods to reflect the seasonality of the contributors’ project participation. We replicated metrics from previous work and added social metrics to the corpus to predict API-domain labels. Social metrics improved the performance of the classifiers compared to using only the issue description text in terms of precision\, recall\, and f-measure. Precision (0.945) increased by 18.7% and F-measure (0.963) by 17.7% for a project with high social activity. These results indicate that social metrics can help capture the patterns of social interactions in a software project and improve the labeling of issues in an issue tracker
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T045900Z
DTEND:20230516T050500Z
DTSTAMP:20240331T110121Z
UID:f28c9959-e434-4f74-aab0-65430e5f8b4f@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models - Christoph Treude\, Hideaki Hata
DESCRIPTION:Implicit gender bias in software development is a well-documented issue\, such as the association of technical roles with men. To address this bias\, it is important to understand it in more detail. This study uses data mining techniques to investigate the extent to which 56 tasks related to software development\, such as assigning GitHub issues and testing\, are affected by implicit gender bias embedded in large language models. We systematically translated each task from English into a genderless language and back\, and investigated the pronouns associated with each task. Based on translating each task 100 times in different permutations\, we identify a significant disparity in the gendered pronoun associations with different tasks. Specifically\, when starting with the pronoun “she”\, requirements elicitation was associated with the pronoun “he” in only 6% of cases\, while testing was associated with “he” in 100% of cases. Additionally\, tasks related to helping others had a 91% association with “he” while the same association for tasks related to asking coworkers was only 52%. These findings reveal a clear pattern of gender bias related to software development tasks and have important implications for addressing this issue both in the training of large language models and in broader society.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T050500Z
DTEND:20230516T051100Z
DTSTAMP:20240331T110121Z
UID:1b7d0b20-2c7e-40fe-8d1f-9bab5b3f4065@conf.researchr.org
CREATED:20230426T151509Z
SUMMARY:[MSR Technical Papers] GitHub OSS Governance File Dataset - Yibo Yan\, Seth Frey\, Amy Zhang\, Vladimir Filkov\, Likang Yin
DESCRIPTION:Open-source Software (OSS) has become a valuable resource in both industry and academia over the last few decades. Despite the innovative structures they develop to support the projects\, OSS projects and their communities have complex needs and face risks such as getting abandoned. To manage the internal social dynamics and community evolution\, OSS developer communities have started relying on written governance documents that assign roles and responsibilities to different community actors. \nTo facilitate the study of the impact and effectiveness of formal governance documents on OSS projects and communities\, we present a longitudinal dataset of 710 GitHub-hosted OSS projects with GOVERNANCE.MD governance files. This dataset includes all commits made to the repository\, all issues and comments created on GitHub\, and all revisions made to the governance file. We hope its availability will foster more research interest in studying how OSS communities govern their projects and the impact of governance files on communities.
LOCATION:Meeting Room 110 - , Melbourne, Australia
LAST-MODIFIED:20230426T151509Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T054500Z
DTEND:20230516T060500Z
DTSTAMP:20240331T110121Z
UID:b95d9894-3c37-41d6-b610-e4ea010fadd4@conf.researchr.org
CREATED:20230426T174501Z
SUMMARY:[MSR Technical Papers] MSR 2023 Doctoral Research Award - Eman Abdullah AlOmar
DESCRIPTION:
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230503T042937Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T060500Z
DTEND:20230516T063500Z
DTSTAMP:20240331T110121Z
UID:3b8e4a51-d22a-4676-b7a5-88cb8175f22b@conf.researchr.org
CREATED:20230426T174501Z
SUMMARY:[MSR Technical Papers] Open Source Software Digital Sociology: Quantifying and Understanding Large Complex Open Source Ecosystems - Minghui Zhou
DESCRIPTION:Open Source Software (OSS) ecosystems have had a tremendous impact on computing and society\, while their formation and sustainability pose great challenges to both practitioners and researchers. We utilize vast collections of open data produced by distributed version control and social media to discover the mechanisms by which such large complex ecosystems form and operate\, which we call OSS digital sociology. We target critical issues ranging from individual learning\, group collaboration\, to ecosystem sustainability\, and software supply chain. We discuss the preliminary promising results and their relevance in practice. \nMinghui zhou is Full Professor of School of Computer Science at Peking University. Her main interest is to mine vast data to investigate how OSS ecosystem works\, and how to invent intelligent systems to help control large complex software systems. She leads several open source initiatives in China involving OSS supply chain and OSS healthcare. She serves on technical oversight committee of Mulan community and advisory expert of openEuler community. She is associate director of Open Source Development Committee of China Computer Federation. She will be Program Co-Chair of ASE 2024.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230503T042943Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T063500Z
DTEND:20230516T070500Z
DTSTAMP:20240331T110121Z
UID:99dc9781-aae0-4edc-8c78-357087173a8d@conf.researchr.org
CREATED:20230503T042816Z
SUMMARY:[MSR Technical Papers] Human-Centered AI for SE: Reflection and Vision - David Lo
DESCRIPTION:Since its inception in the 2000s\, AI for Software Engineering (AI4SE) has grown rapidly\, with the MSR community playing a pivotal role. By analyzing data in various repositories\, AI in its different forms\, e.g.\, data mining\, information retrieval\, machine learning\, natural language processing\, etc.\, has been demonstrated to be able to produce good results for automating many tasks\, including specification mining\, bug and vulnerability discovery\, bug localization\, duplicate bug report identification\, failure detection\, program repair\, technical question answering\, code search\, and many more. AI4SE has much potential to improve software engineers’ productivity and software quality. Due to its potential\, it is currently one of the most popular research areas in the software engineering field. \nTo advance AI4SE\, this talk highlights the need for Human-Centered AI4SE. Without considering humans\, it is easy for AI-powered tools to hinder rather than help humans in their job or introduce unwanted and unacceptable side effects. Human-centered AI4SE puts humans (i.e.\, software practitioners) at the forefront of the design of AI4SE tools\, aiming to amplify and augment software practitioners’ capabilities. This talk will describe some requirements of human-centered AI4SE. Specifically\, among others\, the need to (i) listen to humans\, (ii) learn from (and like) humans\, and (iii) synergize with humans. For the first two requirements\, I will present a reflection on relevant work we have done in the last decade and a vision of what we can do to push forward Human-Centered AI4SE. \nDavid Lo is a Professor of Computer Science and Director of the Information Systems and Technology Cluster at the School of Computing and Information Systems\, Singapore Management University. For nearly two decades\, he has championed AI4SE\, specifically demonstrating how AI – including data mining\, machine learning\, information retrieval\, natural language processing\, and search-based algorithms – can transform passive software engineering data stored in various software repositories into automation and insights. He has published 400+ AI4SE papers that have gathered 25k+ citations. He has won 20+ international awards\, including the IEEE TCSE Distinguished Service award\, two Test-of-Time (or Most Influential Paper) awards\, and six ACM Distinguished Paper awards. He is an IEEE Fellow (for contributions to synergizing software engineering and data mining)\, Fellow of Automated Software Engineering (for significant and sustained contributions to the automated software engineering community)\, ACM Distinguished Member\, and NRF Investigator (2023-28). He served as the GC of MSR’22 and PC Co-Chair of ASE’20 and is serving as a PC Co-Chair of ESEC/FSE’24 and ICSE’25. More information about him and his work can be found at: http://www.mysmu.edu/faculty/davidlo/.
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230503T042948Z
END:VEVENT
BEGIN:VEVENT
DTSTART:20230516T070500Z
DTEND:20230516T073000Z
DTSTAMP:20240331T110121Z
UID:46804253-8756-4075-83a4-922d4790d149@conf.researchr.org
CREATED:20230503T042833Z
SUMMARY:[MSR Technical Papers] Closing - Emad Shihab
DESCRIPTION:
LOCATION:Meeting Room 109 - , Melbourne, Australia
LAST-MODIFIED:20230503T042953Z
END:VEVENT
END:VCALENDAR